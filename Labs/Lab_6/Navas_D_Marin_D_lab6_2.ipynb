{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 6 Parte 2\n",
    "\n",
    "### Reducción de dimensión por extracción de características con PCA y LDA\n",
    "\n",
    "### Universidad de Antioquia\n",
    "\n",
    "### Facultad de Ingeniería\n",
    "\n",
    "### Ingeniería de Sistemas\n",
    "\n",
    "### Ude@ - 2018-II\n",
    "\n",
    "#### Profesor: Antonio Tamayo Herrera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudiantes\n",
    "\n",
    "Nombre: Deiry Sofia Navas Muriel\n",
    "\n",
    "Céduda: 1122140270\n",
    "\n",
    "Nombre: David Alejandro Marín Alzate\n",
    "\n",
    "Cédula: 1041325808"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En esta archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicaciones\n",
    "\n",
    "Este ejercicio tiene como objetivo implementar varias técnicas de extracción de características (PCA y LDA) y usar SVM para resolver un problema de clasificación multietiqueta o multiclase.\n",
    "\n",
    "Para el problema de clasificación usaremos la siguiente base de datos: https://archive.ics.uci.edu/ml/datasets/Cardiotocography\n",
    "\n",
    "#### Abstract: \n",
    "The dataset consists of measurements of fetal heart rate (FHR) and uterine contraction (UC) features on cardiotocograms classified by expert obstetricians.\n",
    "\t\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "LB - FHR baseline (beats per minute)\n",
    "\n",
    "AC - # of accelerations per second\n",
    "\n",
    "FM - # of fetal movements per second\n",
    "\n",
    "UC - # of uterine contractions per second\n",
    "\n",
    "DL - # of light decelerations per second\n",
    "\n",
    "DS - # of severe decelerations per second\n",
    "\n",
    "DP - # of prolongued decelerations per second\n",
    "\n",
    "ASTV - percentage of time with abnormal short term variability\n",
    "\n",
    "MSTV - mean value of short term variability\n",
    "\n",
    "ALTV - percentage of time with abnormal long term variability\n",
    "\n",
    "MLTV - mean value of long term variability\n",
    "\n",
    "Width - width of FHR histogram\n",
    "\n",
    "Min - minimum of FHR histogram\n",
    "\n",
    "Max - Maximum of FHR histogram\n",
    "\n",
    "Nmax - # of histogram peaks\n",
    "\n",
    "Nzeros - # of histogram zeros\n",
    "\n",
    "Mode - histogram mode\n",
    "\n",
    "Mean - histogram mean\n",
    "\n",
    "Median - histogram median\n",
    "\n",
    "Variance - histogram variance\n",
    "\n",
    "Tendency - histogram tendency\n",
    "\n",
    "CLASS - FHR pattern class code (1 to 10)\n",
    "\n",
    "NSP - fetal state class code (N=normal (1); S=suspect (2); P=pathologic (3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analice la base de datos, sus características, su variable de salida y el contexto del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de iniciar a ejecutar las celdas, debe tener instalada la librería mlxtend que usamos en la parte 1 del presente laboratorio. Si aún no la ha instalado, remítase a la guía del laboratorio anterior.\n",
    "\n",
    "Analice y comprenda la siguiente celda de código donde se importan las librerías a usar y se carga la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la base de datos de entrenamiento. dim de X: (2126, 22)\tdim de Y: (2126,)\n",
      "[2 1 1 ... 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from mlxtend.preprocessing import standardize\n",
    "from mlxtend.feature_extraction import PrincipalComponentAnalysis as PCA\n",
    "from mlxtend.feature_extraction import LinearDiscriminantAnalysis as LDA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "import time\n",
    "\n",
    "#cargamos la bd de entrenamiento\n",
    "db = np.loadtxt('DB_Fetal_Cardiotocograms.txt',delimiter='\\t')  # Assuming tab-delimiter\n",
    "\n",
    "X = db[:,0:22]\n",
    "\n",
    "#Solo para dar formato a algunas variables\n",
    "for i in range(1,7):\n",
    "    X[:,i] = X[:,i]*1000\n",
    "\n",
    "X = X\n",
    "Y = db[:,22]\n",
    "\n",
    "#Para darle formato de entero a la variable de salida\n",
    "\n",
    "Y_l = []\n",
    "for i in Y:\n",
    "    Y_l.append(int(i))\n",
    "Y = np.asarray(Y_l)\n",
    "\n",
    "print (\"Dimensiones de la base de datos de entrenamiento. dim de X: \" + str(np.shape(X)) + \"\\tdim de Y: \" + str(np.shape(Y)))\n",
    "Y = Y.reshape(2126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda de código no tiene que completar nada. Analice, comprenda y ejecute el código y tenga en cuenta los resultados para completar la tabla que se le pide más abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error de validación sin aplicar extracción: 0.07712817787226504 +/- 0.05442325724156325\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.6041691303253174 segundos.\n"
     ]
    }
   ],
   "source": [
    "def classification_error(y_est, y_real):\n",
    "    err = 0\n",
    "    for y_e, y_r in zip(y_est, y_real):\n",
    "\n",
    "        if y_e != y_r:\n",
    "            err += 1\n",
    "\n",
    "    return err/np.size(y_est)\n",
    "\n",
    "#Para calcular el costo computacional\n",
    "tiempo_i = time.time()\n",
    "\n",
    "#Creamos el clasificador SVM. Tenga en cuenta que el problema es multiclase. \n",
    "clf = svm.SVC(decision_function_shape='ovr', kernel='rbf', C = 100, gamma=0.0001)\n",
    "\n",
    "#Implemetamos la metodología de validación\n",
    "\n",
    "Errores = np.ones(10)\n",
    "j = 0\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "    #Aquí se entran y se valida el modelo sin hacer selección de características\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    # Entrenamiento el modelo.\n",
    "    model = clf.fit(X_train,y_train)\n",
    "\n",
    "    # Validación del modelo\n",
    "    ypred = model.predict(X_test)\n",
    "    \n",
    "    #######\n",
    "\n",
    "    Errores[j] = classification_error(ypred, y_test)\n",
    "    j+=1\n",
    "\n",
    "print(\"\\nError de validación sin aplicar extracción: \" + str(np.mean(Errores)) + \" +/- \" + str(np.std(Errores)))\n",
    "\n",
    "print (\"\\n\\nTiempo total de ejecución: \" + str(time.time()-tiempo_i) + \" segundos.\")\n",
    "\n",
    "#print str(ypred)\n",
    "#print str(y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "1.1 Al aplicar PCA es necesario estandarizar los datos? Si, No y por qué? En qué consiste dicha estandarización?\n",
    "\n",
    "R/: Si, por que los datos tienen que estar centrados y esto se hacer restando la media\n",
    "    \n",
    "1.2 La proyección de los datos que realiza PCA se hace buscando minimizar o maximizar algo? Explique.\n",
    "\n",
    "R/: busca la proyeccion de los datos en un espacio de menor dimension donde la variabilidad de los datos es maxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "En la siguiente celda, complete el código donde le sea indicado. Consulte la documentación oficial de la librería mlxtend para los métodos de extracción de características. https://rasbt.github.io/mlxtend/user_guide/feature_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2126\n",
      "(2126, 22)\n",
      "\n",
      "Error de validación aplicando extracción: 0.22142793870139074 +/- 0.17001475908401714\n",
      "\n",
      "Eficiencia en validación aplicando extracción: 77.85720612986093%\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.9283039569854736 segundos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.221, 0.17, 0.93)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Extraction Function\n",
    "#Recibe 2 parámetros: 1. el tipo de método de extracción (pca o lda como string), 2. el número componentes (para pca)\n",
    "#o el número de discriminantes (para lda)\n",
    "\n",
    "#Para este laboratorio solo se le pedirá trabajar con PCA, LDA es opcional.\n",
    "\n",
    "def extract_features(tipo, n):\n",
    "    \n",
    "    if tipo == 'pca':\n",
    "    \n",
    "        ext = PCA(n_components=n)\n",
    "    \n",
    "        return ext\n",
    "\n",
    "    elif tipo == 'lda':\n",
    "        \n",
    "        ext = LDA(n_discriminants=n)\n",
    "        \n",
    "        return ext\n",
    "    \n",
    "    else:\n",
    "        print(\"Ingrese un método válido (pca o lda)\\n\")\n",
    "\n",
    "def pca_lda(typeModel='pca',n=2):\n",
    "    #Para calcular el costo computacional\n",
    "    tiempo_i = time.time()\n",
    "    global X\n",
    "    global Y\n",
    "    print(len(Y))\n",
    "    print(np.shape(X))\n",
    "    #Estandarizamos los datos\n",
    "    \n",
    "    X = standardize(X)\n",
    "\n",
    "    #Implemetamos la metodología de validación cross validation con 10 folds\n",
    "\n",
    "    Errores = np.ones(10)\n",
    "    j = 0\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        #Aquí se aplica la extracción de características por PCA\n",
    "        #Complete el código\n",
    "        #Complete el código llamando el método extract_features. Tenga en cuenta lo que le pide el ejercicio 3.1\n",
    "        ex = extract_features(tipo='pca', n=n)\n",
    "\n",
    "        #Fit de PCA\n",
    "        #Complete el código con el fit correspondiente\n",
    "        ex = ex.fit(X)\n",
    "\n",
    "        #Transforme las variables y genere el nuevo espacio de características de menor dimensión\n",
    "        #complete el código aquí para hacer la transformación\n",
    "        X_ex = ex.transform(X)\n",
    "\n",
    "        #Aquí se aplica la extracción de características por LDA\n",
    "\n",
    "        #OPCIONAL\n",
    "\n",
    "        #Complete el código llamando el método extract_features. Tenga en cuenta lo que le pide el ejercicio 3.1\n",
    "        #ex = extract_features(tipo='lda', n=n)\n",
    "        \n",
    "        #Fit de LDA\n",
    "        #ex = ex.fit(X,Y)#Complete el código con el fit correspondiente\n",
    "\n",
    "        #Transforme las variables y genere el nuevo espacio de características de menor dimensión\n",
    "        #X_ex = ex.transform(X)#complete el código aquí para hacer la transformación\n",
    "\n",
    "\n",
    "        #Se aplica CV-10\n",
    "\n",
    "        X_train, X_test = X_ex[train_index], X_ex[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "        #Aquí se entrena y se valida el modelo luego de aplicar extracción de características con PCA o LDA\n",
    "\n",
    "        ######\n",
    "\n",
    "        # Entrenamiento el modelo.\n",
    "        model = clf.fit(X_train,y_train)\n",
    "\n",
    "        # Validación del modelo\n",
    "        ypred = model.predict(X_test)\n",
    "\n",
    "        #######\n",
    "\n",
    "        Errores[j] = classification_error(ypred, y_test)\n",
    "        j+=1\n",
    "\n",
    "\n",
    "    print(\"\\nError de validación aplicando extracción: \" + str(np.mean(Errores)) + \" +/- \" + str(np.std(Errores)))\n",
    "\n",
    "    print(\"\\nEficiencia en validación aplicando extracción: \" + str((1-np.mean(Errores))*100) + \"%\" )\n",
    "\n",
    "    print (\"\\n\\nTiempo total de ejecución: \" + str(time.time()-tiempo_i) + \" segundos.\")\n",
    "    \n",
    "    error = round(np.mean(Errores),3)\n",
    "    ic = round(np.std(Errores),3)\n",
    "    t = round(time.time()-tiempo_i,2)\n",
    "    return error,ic,t\n",
    "\n",
    "    #print str(ypred)\n",
    "    #print str(y_test)\n",
    "pca_lda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2126\n",
      "(2126, 22)\n",
      "\n",
      "Error de validación aplicando extracción: 0.22142793870139074 +/- 0.17001475908401714\n",
      "\n",
      "Eficiencia en validación aplicando extracción: 77.85720612986093%\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.8342940807342529 segundos.\n",
      "2126\n",
      "(2126, 22)\n",
      "\n",
      "Error de validación aplicando extracción: 0.09169324120825582 +/- 0.061564467997647386\n",
      "\n",
      "Eficiencia en validación aplicando extracción: 90.83067587917442%\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.4725189208984375 segundos.\n",
      "2126\n",
      "(2126, 22)\n",
      "\n",
      "Error de validación aplicando extracción: 0.07193949862698203 +/- 0.04841386304281984\n",
      "\n",
      "Eficiencia en validación aplicando extracción: 92.8060501373018%\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.46214890480041504 segundos.\n",
      "2126\n",
      "(2126, 22)\n",
      "\n",
      "Error de validación aplicando extracción: 0.07430463282841704 +/- 0.04391645244688941\n",
      "\n",
      "Eficiencia en validación aplicando extracción: 92.5695367171583%\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.4796321392059326 segundos.\n"
     ]
    }
   ],
   "source": [
    "features = [None,2,10,19,21]\n",
    "\n",
    "errors = np.zeros(len(features))\n",
    "ics = np.zeros(len(features))\n",
    "timers = np.zeros(len(features))\n",
    "\n",
    "errors[0] = 0.077\n",
    "ics[0] = 0.054\n",
    "timers[0] = 0.60\n",
    "\n",
    "for i in range(1,len(features)):\n",
    "    errors[i],ics[i],timers[i] = pca_lda(n=features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "3.1 En la celda de código anterior, varíe los parámetros correspondientes al número de componentes principales a tener en cuenta (use 2, 10, 19 y 21 componentes principales) para PCA y complete la siguiente tabla de resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "df_types = pd.DataFrame({\n",
    "    'Técnicas' : pd.Series(['SVM sin selección','SVM + PCA','SVM + PCA','SVM + PCA','SVM + PCA']),\n",
    "    '# de componentes principales' : pd.Series(features)})\n",
    "df_types[\"Error de validación\"] = errors\n",
    "df_types[\"IC (std)\"] = ics\n",
    "df_types[\"Tiempo de ejecución\"] = timers\n",
    "df_types.set_index(['Técnicas','# de componentes principales'], inplace=True)\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Error de validación</th>\n",
       "      <th>IC (std)</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Técnicas</th>\n",
       "      <th># de componentes principales</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM sin selección</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.077</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">SVM + PCA</th>\n",
       "      <th>2.0</th>\n",
       "      <td>0.221</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.092</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>0.074</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Error de validación  IC (std)  \\\n",
       "Técnicas          # de componentes principales                                  \n",
       "SVM sin selección NaN                                         0.077     0.054   \n",
       "SVM + PCA         2.0                                         0.221     0.170   \n",
       "                  10.0                                        0.092     0.062   \n",
       "                  19.0                                        0.072     0.048   \n",
       "                  21.0                                        0.074     0.044   \n",
       "\n",
       "                                                Tiempo de ejecución  \n",
       "Técnicas          # de componentes principales                       \n",
       "SVM sin selección NaN                                          0.60  \n",
       "SVM + PCA         2.0                                          0.83  \n",
       "                  10.0                                         0.47  \n",
       "                  19.0                                         0.46  \n",
       "                  21.0                                         0.48  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Analizando los resultados del punto anterior que puede decir de la viabilidad de aplicar PCA para hacer reducción de dimensión en este problema?\n",
    "\n",
    "R/: si es viable por que con un espacio de 19 caracteristicas nos da un error en la validacion del 7.2% +- 4.8%, se le estarian quitando 3 dimensiones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Explique en sus palabras la principal ventaja que tiene LDA sobre PCA para resolver problemas de clasificación.\n",
    "\n",
    "R/: el criterio de LDA realiza la proyeccion en la que las distancias entre las medias de cada clase es maxima con respecto a la otra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Explique en sus palabras las diferencias que existen entre los métodos de selección de características y los métodos de extracción de características vistos en el curso.\n",
    "\n",
    "R/:la principal deferencia es que selección de caracteristicas busca son las caracteristicas mas importantes y mas relvantes del problema de tal modo que su nivel predicción no disminuya, mientras que extracción de caracteristicas reduce es la dimension del problema haciendo proyecciones sobre un espacio menor en otras palabras transforma los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0a4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
