{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librerías\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import qgrid\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix,auc,roc_auc_score\n",
    "# import redes neuronales artificiales\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# import random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import maquinas de soporte vectorial\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión data set (4521, 17)\n"
     ]
    }
   ],
   "source": [
    "head_names = ['age', 'job', 'marital', 'education', 'credit', 'balance', 'housing',\n",
    "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
    "       'previous', 'poutcome', 'y']\n",
    "#df_bank = pd.read_csv('bank-full.csv', delimiter=';', header=None,names=head_names,skiprows=1)\n",
    "df_bank = pd.read_csv('bank.csv', delimiter=';', header=None,names=head_names,skiprows=1)\n",
    "print(\"Dimensión data set\",df_bank.shape)\n",
    "#df_bank.head()\n",
    "y = df_bank[\"y\"]\n",
    "y = y.replace(\"no\", 0)\n",
    "y = y.replace(\"yes\", 1)\n",
    "X = df_bank.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carácteristicas categóricas\n",
    "\n",
    "En este caso se debe preprocesar aquellas carácteristicas categorical que el modelo no puede entender y convertirlas a variables númericas, a esto se le conoce como *\"One Hot Encode\"*. Se resuelve con la librería de sklearn o con pandas creando las variables ficticias conocidas **\"Dummy variables\"**.\n",
    "\n",
    "Se debe tener en cuenta que podemos eliminar uno variable \"dummy\" porque si el resto de variables no son debe ser esa, esto quitará redundancia.\n",
    "\n",
    "Este caso corresponde a las carácteristicas job,education,contact,month y las variables binarias como default, housing,loan, contact y  y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bank.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se selecciona las variables tipo 'object', en este caso corresponde a variables categoricas. Esto nos permite separar dichas variables para su tratamiento con el \"One Hot Encoding\" segmentada. \n",
    "\n",
    "En la siguiente celda se observa que la variable mes puede ser reemplazado por un valor númerico directamente y así mismo con las variables binarias, a esto se le conoce como \"Integer encoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df = df_bank.select_dtypes(include=['object']).copy()\n",
    "#obj_df.columns\n",
    "\n",
    "#for column in obj_df.columns:\n",
    "#    print(obj_df[column].value_counts(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar el mes y variables binarias por un valor numerico\n",
    "cat_var = {'month':{'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12},\n",
    "          'housing': {'yes':1,'no':0},\n",
    "          'credit':{'yes':1,'no':0},\n",
    "          'loan' : {'yes':1,'no':0},\n",
    "          'y':{'yes':1,'no':0}\n",
    "         }\n",
    "obj_df.replace(cat_var, inplace=True)\n",
    "\n",
    "#for i in range(df_bank.shape[0]):\n",
    "#    df_bank.at[i, 'month'] = months[df_bank.at[i, 'month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obj_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot Encode job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, aún nos falta 5 variables por aplicar los valores númericos con más de 2 categorías. Tenemos 'job' con 12 categorías, 'marital' con 3, 'education' con 4, 'contact' con 3, por último 'poutcome' con 4.\n",
    "\n",
    "Hay que tener en cuenta que existe una trampa de la variables ficticias creadas y consiste en crear una nueva variable por cada una, llega a ser redundante. Por tanto la solución está eliminar una de las variables categóricas, si hay $d$ número de categorías, use $d-1$ en el modelo, el valor omitido se puede considerar como el valor de referencia y los valores nuevos de las categorías restantes representan el cambio de esta referencia.\n",
    "\n",
    "Dicho lo anterior se resta una categoría a cada variable y las otras 5 variables de categorías enteras esperamos 26 variables, el DataFrame resultante se guarda en **obj_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dummies = ['job', 'marital', 'education', 'contact', 'poutcome']\n",
    "obj_df = pd.get_dummies(obj_df,prefix=cols_dummies, drop_first=True)\n",
    "#len(obj_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de las variables categoricas\n",
    "cat_vars = cols_dummies + list(cat_var.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos disponemos a concatenar las variables tipo enteras con las categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['age','housing', 'loan', 'job_blue-collar','job_entrepreneur', 'job_housemaid', 'job_management', \n",
    "         'job_retired','job_self-employed', 'job_services', 'job_student', 'job_technician','job_unemployed',\n",
    "         'job_unknown', 'marital_married', 'marital_single','education_secondary', 'education_tertiary', \n",
    "         'education_unknown','day', 'month','contact_telephone', 'contact_unknown',  'balance',  'duration', \n",
    "         'campaign', 'pdays', 'previous','credit','poutcome_other','poutcome_success', 'poutcome_unknown', 'y']\n",
    "\n",
    "df_bank_copy = df_bank.copy()\n",
    "df_bank_copy = df_bank_copy.drop(columns=cat_vars)\n",
    "df_bank_copy.head()\n",
    "df_bank_2 = pd.concat([obj_df.T, df_bank_copy.T]).T\n",
    "df_bank_2 = df_bank_2[index]\n",
    "X = df_bank_2[index]\n",
    "y = df_bank_2['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "En nuestro análisis exploratorio, debemos lidiar con los valores faltantes. Al parecer en nuestro caso no hay, sin embargo muchas veces esos valores pueden de diferente formas tales como 0, signos de interrogación o números negativos (según su interpretación). Es así que decidimos ir más allá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.info()\n",
    "#X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Classes \n",
    "\n",
    "Una vez ya tenemos las variables categoricas listas para entrenar, surge otra cuestión. Contamos con un dataset desbalanceado, la clase positiva (el usuario que se suscribió a la campaña) representa un 13% en comparación de la clase negativa. \n",
    "\n",
    "Como primera instancia, vamos a aplicar la técnica de SMOTE para hacer pruebas sintenticas y tratar de mejorar ese porcentaje. No buscamos igualarlo pero si mejorar la situación de desbalanceo al menos un poco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4000\n",
       "1     521\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(y).plot.bar()\n",
    "plt.title('Histograma Y')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequency')\n",
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (3616, 33)\n",
      "Number transactions y_train dataset:  (3616,)\n",
      "Number transactions X_test dataset:  (905, 33)\n",
      "Number transactions y_test dataset:  (905,)\n",
      "Before OverSampling, counts of label '1': 409\n",
      "Before OverSampling, counts of label '0': 3207 \n",
      "\n",
      "After OverSampling, the shape of train_X: (6414, 33)\n",
      "After OverSampling, the shape of train_y: (6414,) \n",
      "\n",
      "After OverSampling, counts of label '1': 3207\n",
      "After OverSampling, counts of label '0': 3207\n"
     ]
    }
   ],
   "source": [
    "index = ['age','housing', 'loan', 'job_blue-collar','job_entrepreneur', 'job_housemaid', 'job_management', \n",
    "         'job_retired','job_self-employed', 'job_services', 'job_student', 'job_technician','job_unemployed',\n",
    "         'job_unknown', 'marital_married', 'marital_single','education_secondary', 'education_tertiary', \n",
    "         'education_unknown','day', 'month','contact_telephone', 'contact_unknown',  'balance',  'duration', \n",
    "         'campaign', 'pdays', 'previous','credit','poutcome_other','poutcome_success', 'poutcome_unknown']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_val.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_val.shape)\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "#sm = SMOTE(sampling_strategy=0.16,random_state=2)\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=2)\n",
    "\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "\n",
    "X = X_train_res\n",
    "Y = y_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "def measure_train(classifier):\n",
    "    \n",
    "    cv_results = pd.DataFrame(classifier.cv_results_)[['param_n_neighbors', 'mean_train_score','std_train_score','mean_test_score','std_test_score','mean_score_time']]\n",
    "  \n",
    "    print(cv_results)    \n",
    "    y_pred = classifier.predict(X_train)\n",
    "    matrix = confusion_matrix(y_train, y_pred)    \n",
    "   # print('Recall manual'+ str(recall(matrix)))\n",
    "    #print('Recall auto '+ str(recall_score(y_train, y_pred)))\n",
    "    error = ErrorClass(y_train, y_pred) \n",
    "    print('Error de entrenamiento = ' + str(error))\n",
    "    print('Mejor parámetro: '+str(classifier.best_params_))\n",
    "    \n",
    "def measure_val(classifier):\n",
    "    \n",
    "    y_pred = classifier.predict(X_val)\n",
    "    print (confusion_matrix(y_val, y_pred))\n",
    "    error = ErrorClass(y_val,y_pred) \n",
    "    print('Error de evaluación final = ' + str(error))\n",
    "\n",
    "def measure_scoring(classifier):\n",
    "    cv_results = pd.DataFrame(classifier.cv_results_)[['param_n_neighbors','mean_test_Error','mean_test_AUC','mean_train_Error','mean_train_AUC']]\n",
    "    y_pred = classifier.predict(X_train)\n",
    "    error = ErrorClass(y_train, y_pred) \n",
    "    print('Error de entrenamiento = ' + str(error))\n",
    "    print(cv_results)\n",
    "\n",
    "def measure_val_scoring(classifier):\n",
    "    \n",
    "    params = classifier.best_params_\n",
    "    score = classifier.best_score_\n",
    "    print ('\\n Mejor parámetro '+str(params) + ' mejor valor:'+str(score))\n",
    "    y_pred = classifier.predict(X_val)\n",
    "    error = ErrorClass(y_pred,y_val) \n",
    "    print('Error de evaluación final = ' + str(error))\n",
    "    \n",
    "    \n",
    "    #Para calcular el error en los problemas de clasificación\n",
    "def ErrorClass(Y,Y_lest):\n",
    "    error = 1 - np.sum(Y_lest == Y)/len(Y)    \n",
    "    return error\n",
    "\n",
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "\n",
    "def recall(matrix):\n",
    "    return (matrix[0,0]/(matrix[0,0]+matrix(1,0)))\n",
    "\n",
    "scoring = {'tp': make_scorer(tp), 'tn': make_scorer(tn),\n",
    "           'fp': make_scorer(fp), 'fn': make_scorer(fn)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(X, Y, cv=4, scoring=make_scorer(ErrorClass), refit='AUC'):\n",
    "    \n",
    "    parameters = {}\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "    X_norm = scaler.transform(X)\n",
    "    # creamos el clasificador\n",
    "    gnb = GaussianNB()\n",
    "    classifier = GridSearchCV(gnb, parameters, cv=cv, scoring=scoring, refit=refit)\n",
    "    classifier.fit(X_norm, Y)\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "def naiveBayes2(clf, X_train, y_train, X_test):\n",
    "    # create classifier\n",
    "    clf = clf\n",
    "    # fit it to training data\n",
    "    clf.fit(X_train,y_train)\n",
    "    # predict using test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Compute predicted probabilities: y_pred_prob\n",
    "    y_pred_prob = clf.predict_proba(X_test)\n",
    "    #for fun: train-set predictions\n",
    "    train_pred = clf.predict(X_train)\n",
    "    print('train-set confusion matrix:\\n', confusion_matrix(y_train,train_pred)) \n",
    "    return y_pred, y_pred_prob\n",
    "\n",
    "def print_scores(y_test,y_pred,y_pred_prob):\n",
    "    print('test-set confusion matrix:\\n', confusion_matrix(y_test,y_pred)) \n",
    "    print(\"recall score: \", recall_score(y_test,y_pred))\n",
    "    print(\"precision score: \", precision_score(y_test,y_pred))\n",
    "    print(\"f1 score: \", f1_score(y_test,y_pred))\n",
    "    print(\"accuracy score: \", accuracy_score(y_test,y_pred))\n",
    "    print(\"ROC AUC: {}\".format(roc_auc_score(y_test, y_pred_prob[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(neighbors=1):\n",
    "    Folds = 4\n",
    "    random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    Error = np.zeros(Folds)\n",
    "    Error_eval = np.zeros(Folds)\n",
    "    j = 0\n",
    "   \n",
    "    \n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:].astype(float)\n",
    "        Ytrain = Y[train].astype(float)\n",
    "        Xtest = X[test,:].astype(float)\n",
    "        Ytest = Y[test].astype(float)\n",
    "        \n",
    "        #Normalizamos los datos\n",
    "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "        Xtrain = scaler.transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "        \n",
    "        # creamos el clasificador\n",
    "        classifier = KNeighborsClassifier(n_neighbors=neighbors)  \n",
    "        classifier.fit(Xtrain, Ytrain)\n",
    "        \n",
    "        y_est = classifier.predict(Xtrain)\n",
    "        \n",
    "        y_pred = classifier.predict(Xtest)\n",
    "        \n",
    "        y_val_pred = classifier.predict(X_val)\n",
    "        \n",
    "        Error_eval[j] = ErrorClass(y_val_pred, y_val)\n",
    "        \n",
    "        Error[j] = ErrorClass(y_pred,Ytest)\n",
    "        \n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(y_est.ravel() == Ytrain.ravel())\n",
    "        EficienciaVal[j] = np.mean(y_pred.ravel() == Ytest.ravel())\n",
    "        j += 1\n",
    "        \n",
    "       \n",
    "              \n",
    "    print('Número vecinos: '+ str(neighbors))    \n",
    "    print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
    "    print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
    "    print('Error durante la validación = ' + str(np.mean(Error)) + '+-' + str(np.std(Error)))\n",
    "    print('Error de evalución final = ' + str(np.mean(Error_eval)) + '+-' + str(np.std(Error_eval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X, Y, neighbors=[5,10], cv=4, scoring=make_scorer(ErrorClass), refit='AUC'):\n",
    "    \n",
    "    parameters = {\n",
    "    'n_neighbors': neighbors}\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "    X_norm = scaler.transform(X)\n",
    "    # creamos el clasificador\n",
    "    knn = KNeighborsClassifier()\n",
    "    classifier = GridSearchCV(knn, parameters, cv=cv, scoring=scoring, refit=refit)\n",
    "    classifier.fit(X_norm, Y)\n",
    "    \n",
    "    return classifier\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_KNN(X, Y, neighbors=[5,10], cv=4):\n",
    "    \n",
    "    parameters = {\n",
    "    'n_neighbors': neighbors}\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "    X_norm = scaler.transform(X)\n",
    "    # creamos el clasificador\n",
    "    knn = KNeighborsClassifier()\n",
    "    classifier = GridSearchCV(knn, parameters, cv=cv)\n",
    "    classifier.fit(X_norm, Y)\n",
    "    \n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales Artificiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficiencia durante el entrenamiento = 1.0+-0.0\n",
      "Eficiencia durante la validación = 0.51481+-0.0\n"
     ]
    }
   ],
   "source": [
    "#Mean Absolute Percentage Error para los problemas de regresión\n",
    "def MAPE(Y_est,Y):\n",
    "    N = np.size(Y)\n",
    "    mape = np.sum(abs((Y_est.reshape(N,1) - Y.reshape(N,1))/Y.reshape(N,1)))/N\n",
    "    return mape\n",
    "\n",
    "def neuralNetwork(hidden=(28,)):\n",
    "    Folds = 4\n",
    "    random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    j = 0\n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:].astype(float)\n",
    "        Ytrain = Y[train].astype(float)\n",
    "        Xtest = X[test,:].astype(float)\n",
    "        Ytest = Y[test].astype(float)\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        media = np.mean(Xtrain)\n",
    "        desvia = np.std(Xtrain)\n",
    "        Xtrain = preprocessing.scale(Xtrain)\n",
    "        Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "\n",
    "        #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "        mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=hidden, max_iter=500 )\n",
    "        mlp.fit(Xtrain,Ytrain)\n",
    "\n",
    "        #Validación con las muestras de entrenamiento\n",
    "        Ytrain_pred = mlp.predict(Xtrain)\n",
    "\n",
    "        #Validación con las muestras de test    \n",
    "        Yest = mlp.predict(Xtest)\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(Ytrain_pred == Ytrain)\n",
    "        EficienciaVal[j] = np.mean(Yest == Ytest)\n",
    "        j += 1\n",
    "    \n",
    "    mean = round(np.mean(EficienciaTrain),5)\n",
    "    std = round(np.std(EficienciaTrain),5)\n",
    "    \n",
    "    meanVal = round(np.mean(EficienciaVal),5)\n",
    "    stdVal = round(np.std(EficienciaVal),5)\n",
    "    \n",
    "    return mean,std,meanVal,stdVal\n",
    "\n",
    "mean,std,meanVal,stdVal = neuralNetwork()\n",
    "print('Eficiencia durante el entrenamiento = ' + str(mean) + '+-' + str(std))\n",
    "print('Eficiencia durante la validación = ' + str(np.mean(meanVal)) + '+-' + str(np.std(stdVal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(num_tree=5, max_var=None):\n",
    "    #Validamos el modelo\n",
    "    Folds = 4\n",
    "    #random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    j = 0\n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:]\n",
    "        Ytrain = Y[train]\n",
    "        Xtest = X[test,:]\n",
    "        Ytest = Y[test]\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        media = np.mean(Xtrain)\n",
    "        desvia = np.std(Xtrain)\n",
    "        Xtrain = sc.stats.stats.zscore(Xtrain)\n",
    "        Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "\n",
    "        #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "        model = RandomForestClassifier(n_estimators = num_tree, max_features = max_var)\n",
    "        model.fit(X=Xtrain, y=Ytrain)\n",
    "\n",
    "        #Validación\n",
    "        Ytrain_pred = model.predict(Xtrain)#Use el modelo previamente entrenado para hacer predicciones con las mismas muestras de entrenamiento\n",
    "        Yest =  model.predict(Xtest)#Use el modelo previamente entrenado para hacer predicciones con las muestras de test\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(Ytrain_pred.ravel() == Ytrain.ravel())\n",
    "        EficienciaVal[j] = np.mean(Yest.ravel() == Ytest.ravel())\n",
    "        j += 1\n",
    "\n",
    "    mean = round(np.mean(EficienciaTrain),4)\n",
    "    std = round(np.std(EficienciaTrain),4)\n",
    "    \n",
    "    meanVal = round(np.mean(EficienciaVal),4)\n",
    "    stdVal = round(np.std(EficienciaVal),4)\n",
    "    \n",
    "    return (mean, std, meanVal, stdVal)\n",
    "\n",
    "# entrenamiento de varios modelos\n",
    "num_trees = [1,2,3,4,5,10,20,50,100]\n",
    "var_per_nodes = [1,2,3,4,5,10,15,20]\n",
    "nums = np.zeros(len(num_trees) * len(var_per_nodes))\n",
    "vars_per_nodes = np.zeros(len(num_trees) * len(var_per_nodes))\n",
    "efi_val = np.zeros(len(num_trees) * len(var_per_nodes))\n",
    "interval = np.zeros(len(num_trees) * len(var_per_nodes))\n",
    "\n",
    "j = 0\n",
    "for num in num_trees:\n",
    "    for var in var_per_nodes:\n",
    "        mean, std, meanVal, stdVal = randomForest(num,var)\n",
    "        efi_val[j] = meanVal;\n",
    "        interval[j] = stdVal;\n",
    "        vars_per_nodes[j] = var\n",
    "        nums[j] = num\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Eficiencia en validacion</th>\n",
       "      <th>Intervalo de confianza</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Numero de arboles</th>\n",
       "      <th>Variables analizadas por nodo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">1.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5383</td>\n",
       "      <td>0.1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.5337</td>\n",
       "      <td>0.0758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.4941</td>\n",
       "      <td>0.0114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.0106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.5008</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">3.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.4998</td>\n",
       "      <td>0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.4980</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.4995</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">4.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.4997</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.4853</td>\n",
       "      <td>0.0257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5009</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">10.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">20.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.4989</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.4995</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">50.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">100.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Eficiencia en validacion  \\\n",
       "Numero de arboles Variables analizadas por nodo                             \n",
       "1.0               1.0                                              0.5383   \n",
       "                  2.0                                              0.5337   \n",
       "                  3.0                                              0.4941   \n",
       "                  4.0                                              0.5000   \n",
       "                  5.0                                              0.5000   \n",
       "                  10.0                                             0.5000   \n",
       "                  15.0                                             0.5000   \n",
       "                  20.0                                             0.5000   \n",
       "2.0               1.0                                              0.4889   \n",
       "                  2.0                                              0.5008   \n",
       "                  3.0                                              0.5000   \n",
       "                  4.0                                              0.5026   \n",
       "                  5.0                                              0.5000   \n",
       "                  10.0                                             0.5000   \n",
       "                  15.0                                             0.5000   \n",
       "                  20.0                                             0.5000   \n",
       "3.0               1.0                                              0.4998   \n",
       "                  2.0                                              0.4980   \n",
       "                  3.0                                              0.4995   \n",
       "                  4.0                                              0.5000   \n",
       "                  5.0                                              0.5000   \n",
       "                  10.0                                             0.5000   \n",
       "                  15.0                                             0.5000   \n",
       "                  20.0                                             0.5000   \n",
       "4.0               1.0                                              0.4997   \n",
       "                  2.0                                              0.4853   \n",
       "                  3.0                                              0.5009   \n",
       "                  4.0                                              0.5000   \n",
       "                  5.0                                              0.5000   \n",
       "                  10.0                                             0.5000   \n",
       "...                                                                   ...   \n",
       "10.0              3.0                                              0.5000   \n",
       "                  4.0                                              0.5000   \n",
       "                  5.0                                              0.5000   \n",
       "                  10.0                                             0.5000   \n",
       "                  15.0                                             0.5000   \n",
       "                  20.0                                             0.5000   \n",
       "20.0              1.0                                              0.4989   \n",
       "                  2.0                                              0.4995   \n",
       "                  3.0                                              0.5000   \n",
       "                  4.0                                              0.5000   \n",
       "                  5.0                                              0.5000   \n",
       "                  10.0                                             0.5000   \n",
       "                  15.0                                             0.5000   \n",
       "                  20.0                                             0.5000   \n",
       "50.0              1.0                                              0.5221   \n",
       "                  2.0                                              0.5000   \n",
       "                  3.0                                              0.5000   \n",
       "                  4.0                                              0.5000   \n",
       "                  5.0                                              0.5000   \n",
       "                  10.0                                             0.5000   \n",
       "                  15.0                                             0.5000   \n",
       "                  20.0                                             0.5000   \n",
       "100.0             1.0                                              0.5016   \n",
       "                  2.0                                              0.5000   \n",
       "                  3.0                                              0.5000   \n",
       "                  4.0                                              0.5000   \n",
       "                  5.0                                              0.5000   \n",
       "                  10.0                                             0.5000   \n",
       "                  15.0                                             0.5000   \n",
       "                  20.0                                             0.5000   \n",
       "\n",
       "                                                 Intervalo de confianza  \n",
       "Numero de arboles Variables analizadas por nodo                          \n",
       "1.0               1.0                                            0.1073  \n",
       "                  2.0                                            0.0758  \n",
       "                  3.0                                            0.0114  \n",
       "                  4.0                                            0.0000  \n",
       "                  5.0                                            0.0000  \n",
       "                  10.0                                           0.0000  \n",
       "                  15.0                                           0.0000  \n",
       "                  20.0                                           0.0000  \n",
       "2.0               1.0                                            0.0106  \n",
       "                  2.0                                            0.0013  \n",
       "                  3.0                                            0.0000  \n",
       "                  4.0                                            0.0046  \n",
       "                  5.0                                            0.0000  \n",
       "                  10.0                                           0.0000  \n",
       "                  15.0                                           0.0000  \n",
       "                  20.0                                           0.0000  \n",
       "3.0               1.0                                            0.0068  \n",
       "                  2.0                                            0.0035  \n",
       "                  3.0                                            0.0008  \n",
       "                  4.0                                            0.0000  \n",
       "                  5.0                                            0.0000  \n",
       "                  10.0                                           0.0000  \n",
       "                  15.0                                           0.0000  \n",
       "                  20.0                                           0.0000  \n",
       "4.0               1.0                                            0.0009  \n",
       "                  2.0                                            0.0257  \n",
       "                  3.0                                            0.0016  \n",
       "                  4.0                                            0.0000  \n",
       "                  5.0                                            0.0000  \n",
       "                  10.0                                           0.0000  \n",
       "...                                                                 ...  \n",
       "10.0              3.0                                            0.0000  \n",
       "                  4.0                                            0.0000  \n",
       "                  5.0                                            0.0000  \n",
       "                  10.0                                           0.0000  \n",
       "                  15.0                                           0.0000  \n",
       "                  20.0                                           0.0000  \n",
       "20.0              1.0                                            0.0011  \n",
       "                  2.0                                            0.0008  \n",
       "                  3.0                                            0.0000  \n",
       "                  4.0                                            0.0000  \n",
       "                  5.0                                            0.0000  \n",
       "                  10.0                                           0.0000  \n",
       "                  15.0                                           0.0000  \n",
       "                  20.0                                           0.0000  \n",
       "50.0              1.0                                            0.0338  \n",
       "                  2.0                                            0.0000  \n",
       "                  3.0                                            0.0000  \n",
       "                  4.0                                            0.0000  \n",
       "                  5.0                                            0.0000  \n",
       "                  10.0                                           0.0000  \n",
       "                  15.0                                           0.0000  \n",
       "                  20.0                                           0.0000  \n",
       "100.0             1.0                                            0.0020  \n",
       "                  2.0                                            0.0000  \n",
       "                  3.0                                            0.0000  \n",
       "                  4.0                                            0.0000  \n",
       "                  5.0                                            0.0000  \n",
       "                  10.0                                           0.0000  \n",
       "                  15.0                                           0.0000  \n",
       "                  20.0                                           0.0000  \n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Numero de arboles' : pd.Series(nums), \n",
    "    'Variables analizadas por nodo' : pd.Series(vars_per_nodes)})\n",
    "df_types[\"Eficiencia en validacion\"] = efi_val\n",
    "df_types[\"Intervalo de confianza\"] = interval\n",
    "df_types['Variables analizadas por nodo'] = vars_per_nodes\n",
    "df_types.set_index(['Numero de arboles','Variables analizadas por nodo'], inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máquinas de Soporte Vectorial con kernel lineal y con kernel RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lineal kernel and rbf kernel\n",
    "def SVM(kernel='linear', c=0.001 ,gamma=0):\n",
    "\n",
    "    if gamma is 0:\n",
    "        gamma = 'auto'\n",
    "        \n",
    "    #Validamos el modelo\n",
    "    Folds = 4\n",
    "    random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    j = 0\n",
    "    percentVectors = np.zeros(Folds)\n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:].astype(float)\n",
    "        Ytrain = Y[train].astype(float)\n",
    "        Xtest = X[test,:].astype(float)\n",
    "        Ytest = Y[test].astype(float)\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "        Xtrain = scaler.transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "\n",
    "        #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "        modelo = SVC(C= c,kernel=kernel,gamma=gamma,  decision_function_shape='ovo')\n",
    "        modelo.fit(Xtrain, Ytrain)\n",
    "        \n",
    "        #Calculamos el porcentaje de vector de soporte\n",
    "        percentVectors[j] = (len(modelo.support_vectors_)/len(Xtrain))\n",
    "\n",
    "        #Validación\n",
    "        Ytrain_pred = modelo.predict(Xtrain)\n",
    "        Yest = modelo.predict(Xtest)\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(Ytrain_pred.ravel() == Ytrain.ravel())\n",
    "        EficienciaVal[j] = np.mean(Yest.ravel() == Ytest.ravel())\n",
    "        j += 1\n",
    "\n",
    "        \n",
    "    #print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
    "    #print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
    "    #print('% Vectore de soporte = ', modelo.n_support_.sum()/720)\n",
    "    mean = round(np.mean(EficienciaVal),5)\n",
    "    std = round(np.std(EficienciaVal),5)\n",
    "    percent = round(percentVectors.sum()/4, 5)\n",
    "    return mean,std,percent\n",
    "\n",
    "#mean,std,percent = SVM(kernel='linear',c=1, gamma=0)\n",
    "\n",
    "#print('Eficiencia durante el entrenamiento = ' + str(np.mean(mean)) + '+-' + str(np.std(std)))\n",
    "#print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
    "#print('% Vectore de soporte = ', percent)\n",
    "\n",
    "kernels = ['lineal','lineal','lineal','lineal','lineal','lineal','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf']\n",
    "cs = [0.001,0.01,0.1,1,10,100,0.001,0.001,0.001,0.01,0.01,0.01,0.1,0.1,0.1,1,1,1,10,10,10,100,100,100]\n",
    "gammas = [0,0,0,0,0,0,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1]\n",
    "medias = np.zeros(len(kernels))\n",
    "stds = np.zeros(len(kernels))\n",
    "percents = np.zeros(len(kernels))\n",
    "\n",
    "for i in range(0,len(kernels)):\n",
    "    if kernels[i] is 'lineal':\n",
    "        kernel = 'linear'\n",
    "    elif kernels[i] is 'rbf':\n",
    "        kernel =  'rbf'\n",
    "    medias[i],stds[i],percents[i] = SVM(kernel=kernel, c=cs[i], gamma=gammas[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Eficiencia en validacion</th>\n",
       "      <th>Intervalo de confianza</th>\n",
       "      <th>% de Vectores de Soporte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">lineal</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>21.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <th>0.00</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <th>0.00</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.000</th>\n",
       "      <th>0.00</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.000</th>\n",
       "      <th>0.00</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">rbf</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.95262</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.73543</td>\n",
       "      <td>0.06313</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.54132</td>\n",
       "      <td>0.01192</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.010</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.96322</td>\n",
       "      <td>0.05832</td>\n",
       "      <td>70.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.81510</td>\n",
       "      <td>0.07487</td>\n",
       "      <td>80.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.54132</td>\n",
       "      <td>0.01192</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.100</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.98784</td>\n",
       "      <td>0.02070</td>\n",
       "      <td>20.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.93578</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>43.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.58295</td>\n",
       "      <td>0.01971</td>\n",
       "      <td>98.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1.000</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.99517</td>\n",
       "      <td>0.00837</td>\n",
       "      <td>7.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.96649</td>\n",
       "      <td>0.05660</td>\n",
       "      <td>32.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.88324</td>\n",
       "      <td>0.08383</td>\n",
       "      <td>86.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10.000</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.99610</td>\n",
       "      <td>0.00675</td>\n",
       "      <td>5.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.96743</td>\n",
       "      <td>0.05498</td>\n",
       "      <td>31.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.89025</td>\n",
       "      <td>0.08627</td>\n",
       "      <td>85.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">100.000</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.99610</td>\n",
       "      <td>0.00675</td>\n",
       "      <td>5.498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.96743</td>\n",
       "      <td>0.05498</td>\n",
       "      <td>31.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.89025</td>\n",
       "      <td>0.08627</td>\n",
       "      <td>85.869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Eficiencia en validacion  Intervalo de confianza  \\\n",
       "Kernel C       gamma                                                     \n",
       "lineal 0.001   0.00                    1.00000                 0.00000   \n",
       "       0.010   0.00                    1.00000                 0.00000   \n",
       "       0.100   0.00                    1.00000                 0.00000   \n",
       "       1.000   0.00                    1.00000                 0.00000   \n",
       "       10.000  0.00                    1.00000                 0.00000   \n",
       "       100.000 0.00                    1.00000                 0.00000   \n",
       "rbf    0.001   0.01                    0.95262                 0.06444   \n",
       "               0.10                    0.73543                 0.06313   \n",
       "               1.00                    0.54132                 0.01192   \n",
       "       0.010   0.01                    0.96322                 0.05832   \n",
       "               0.10                    0.81510                 0.07487   \n",
       "               1.00                    0.54132                 0.01192   \n",
       "       0.100   0.01                    0.98784                 0.02070   \n",
       "               0.10                    0.93578                 0.07820   \n",
       "               1.00                    0.58295                 0.01971   \n",
       "       1.000   0.01                    0.99517                 0.00837   \n",
       "               0.10                    0.96649                 0.05660   \n",
       "               1.00                    0.88324                 0.08383   \n",
       "       10.000  0.01                    0.99610                 0.00675   \n",
       "               0.10                    0.96743                 0.05498   \n",
       "               1.00                    0.89025                 0.08627   \n",
       "       100.000 0.01                    0.99610                 0.00675   \n",
       "               0.10                    0.96743                 0.05498   \n",
       "               1.00                    0.89025                 0.08627   \n",
       "\n",
       "                      % de Vectores de Soporte  \n",
       "Kernel C       gamma                            \n",
       "lineal 0.001   0.00                     21.604  \n",
       "       0.010   0.00                      3.264  \n",
       "       0.100   0.00                      1.902  \n",
       "       1.000   0.00                      1.731  \n",
       "       10.000  0.00                      1.731  \n",
       "       100.000 0.00                      1.731  \n",
       "rbf    0.001   0.01                    100.000  \n",
       "               0.10                    100.000  \n",
       "               1.00                    100.000  \n",
       "       0.010   0.01                     70.439  \n",
       "               0.10                     80.698  \n",
       "               1.00                    100.000  \n",
       "       0.100   0.01                     20.538  \n",
       "               0.10                     43.763  \n",
       "               1.00                     98.971  \n",
       "       1.000   0.01                      7.063  \n",
       "               0.10                     32.138  \n",
       "               1.00                     86.732  \n",
       "       10.000  0.01                      5.504  \n",
       "               0.10                     31.836  \n",
       "               1.00                     85.869  \n",
       "       100.000 0.01                      5.498  \n",
       "               0.10                     31.836  \n",
       "               1.00                     85.869  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "\n",
    "df_types = pd.DataFrame({\n",
    "    'Kernel' : pd.Series(kernels),\n",
    "    'C' : pd.Series(cs),\n",
    "    'gamma' : pd.Series(gammas)})\n",
    "df_types[\"Eficiencia en validacion\"] = medias\n",
    "df_types[\"Intervalo de confianza\"] = stds\n",
    "df_types[\"% de Vectores de Soporte\"] = percents*100\n",
    "df_types.set_index(['Kernel','C','gamma'], inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número vecinos: 1\n",
      "Eficiencia durante el entrenamiento = 1.0+-0.0\n",
      "Eficiencia durante la validación = 0.9540178891099342+-0.053580010886694625\n",
      "Error durante la validación = 0.045982110890065736+-0.053580010886694625\n",
      "Error de evalución final = 0.1759668508287293+-0.08214551847885414\n"
     ]
    }
   ],
   "source": [
    "X = X_train_res\n",
    "Y = y_train_res\n",
    "\n",
    "kNN(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-set confusion matrix:\n",
      " [[22347    12]\n",
      " [    0  3577]]\n",
      "test-set confusion matrix:\n",
      " [[9578    5]\n",
      " [   3 1530]]\n",
      "recall score:  0.9980430528375733\n",
      "precision score:  0.996742671009772\n",
      "f1 score:  0.997392438070404\n",
      "accuracy score:  0.9992803166606693\n",
      "ROC AUC: 0.999795449364392\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)\n",
    "y_pred, y_pred_prob = naiveBayes2(GaussianNB(), X_train, y_train, X_test)\n",
    "print_scores(y_test,y_pred,y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selección del modelo por eficiencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neighbors=[1,3,5,10]\n",
    "\n",
    "#def KNN(X, Y, neighbors=[5,10], cv=4, scoring=make_scorer(ErrorClass)):\n",
    "skf = StratifiedKFold(n_splits=4, random_state=42)\n",
    "#kNN()\n",
    "print('Selección del modelo por eficiencia')\n",
    "classifier = train_KNN(X,Y,neighbors, skf)\n",
    "\n",
    "measure_train(classifier)\n",
    "measure_val(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('La selección del modelo con AUC \\n')\n",
    "scoring = {'AUC': 'roc_auc', 'Error': make_scorer(ErrorClass)}\n",
    "classifier_2 = KNN(X,Y, neighbors, skf, scoring, 'AUC')\n",
    "measure_scoring(classifier_2)\n",
    "measure_val_scoring(classifier_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    \n",
    "    random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    j = 0\n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:]\n",
    "        Ytrain = Y[train]\n",
    "        Xtest = X[test,:]\n",
    "        Ytest = Y[test]\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        media = np.mean(Xtrain)\n",
    "        desvia = np.std(Xtrain)\n",
    "        Xtrain = sc.stats.stats.zscore(Xtrain)\n",
    "        Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tener en cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count           4521\n",
       "unique            12\n",
       "top       management\n",
       "freq             969\n",
       "Name: job, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank['job'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36954, 17)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank[df_bank['pdays'] == -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df_bank[\"y\"]\n",
    "out = out.replace(\"no\", 0)\n",
    "out = out.replace(\"yes\", 1)\n",
    "x = df_bank[\"education\"]\n",
    "y = df_bank[\"job\"]\n",
    "\n",
    "#_ = sns.swarmplot(x='duration', y='age', data=df_bank)\n",
    "#plt.hist(y)\n",
    "# Label the axes\n",
    "plt.title('Age vs housing', fontsize=14)\n",
    "plt.xlabel('Edad')\n",
    "plt.ylabel('duration')\n",
    "plt.scatter(x,y,c=out,cmap=\"Accent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.swarmplot(x=\"housing\", y=\"age\", data=df_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#print(\"Tipos datos\", df_bank.dtypes)\n",
    "df_bank[df_bank['poutcome'] != 'unknown']\n",
    "df_success = df_bank[df_bank['y'] == 'yes']\n",
    "df_no_success = df_bank[df_bank['y'] == 'no']\n",
    "\n",
    "print(\"Muestras de exito \",df_success.shape, \"Muestras de no éxito\",df_no_success.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_bank.boxplot('age','job',rot=60)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0a4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
