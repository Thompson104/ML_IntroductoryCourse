{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#Importación de librerías\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import qgrid\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from random import randint\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix,auc,roc_auc_score\n",
    "# import redes neuronales artificiales\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# import random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import maquinas de soporte vectorial\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión data set (45211, 17)\n",
      "Muestras negativas: 39922\n",
      "Muestras positivas: 5289\n"
     ]
    }
   ],
   "source": [
    "head_names = ['age', 'job', 'marital', 'education', 'credit', 'balance', 'housing',\n",
    "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
    "       'previous', 'poutcome', 'y']\n",
    "df_bank = pd.read_csv('bank-full.csv', delimiter=';', header=None,names=head_names,skiprows=1)\n",
    "#df_bank = pd.read_csv('bank.csv', delimiter=';', header=None,names=head_names,skiprows=1)\n",
    "print(\"Dimensión data set\",df_bank.shape)\n",
    "tam_muestras = df_bank.shape[0]\n",
    "tam_caract = df_bank.shape[1]\n",
    "\n",
    "\n",
    "tam_neg = df_bank[\"y\"].value_counts().values[0]\n",
    "tam_pos = df_bank[\"y\"].value_counts().values[1]\n",
    "\n",
    "print(\"Muestras negativas: \"+str(tam_neg))\n",
    "print(\"Muestras positivas: \"+ str(tam_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionamiento del dataset\n",
    "\n",
    "Se busca igualar el conjunto de datos, se selecciona todo el conjunto de muestras exitos y aleatoriamente las mismas muestras del conjunto de muestras negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo dataset: (10578, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>credit</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2343</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>56</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>45</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>41</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1270</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>55</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2476</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>54</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>184</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age         job  marital  education credit  balance housing loan  \\\n",
       "83    59      admin.  married  secondary     no     2343     yes   no   \n",
       "86    56      admin.  married  secondary     no       45      no   no   \n",
       "87    41  technician  married  secondary     no     1270     yes   no   \n",
       "129   55    services  married  secondary     no     2476     yes   no   \n",
       "168   54      admin.  married   tertiary     no      184      no   no   \n",
       "\n",
       "     contact  day month  duration  campaign  pdays  previous poutcome    y  \n",
       "83   unknown    5   may      1042         1     -1         0  unknown  yes  \n",
       "86   unknown    5   may      1467         1     -1         0  unknown  yes  \n",
       "87   unknown    5   may      1389         1     -1         0  unknown  yes  \n",
       "129  unknown    5   may       579         1     -1         0  unknown  yes  \n",
       "168  unknown    5   may       673         2     -1         0  unknown  yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_yes = df_bank[df_bank[\"y\"] == \"yes\"]\n",
    "dataset_no = df_bank[df_bank[\"y\"] == \"no\"].iloc[[randint(0, tam_neg) for p in range(0, tam_pos)],:]\n",
    "df_bank_new = pd.concat([dataset_yes,dataset_no])\n",
    "print(\"Nuevo dataset: \"+str(df_bank_new.shape))\n",
    "df_bank_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carácteristicas categóricas\n",
    "\n",
    "En este caso se debe preprocesar aquellas carácteristicas categorical que el modelo no puede entender y convertirlas a variables númericas, a esto se le conoce como *\"One Hot Encode\"*. Se resuelve con la librería de sklearn o con pandas creando las variables ficticias conocidas **\"Dummy variables\"**.\n",
    "\n",
    "Se debe tener en cuenta que podemos eliminar uno variable \"dummy\" porque si el resto de variables no son debe ser esa, esto quitará redundancia.\n",
    "\n",
    "Este caso corresponde a las carácteristicas job,education,contact,month y las variables binarias como default, housing,loan, contact y  y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bank.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se selecciona las variables tipo 'object', en este caso corresponde a variables categoricas. Esto nos permite separar dichas variables para su tratamiento con el \"One Hot Encoding\" segmentada. \n",
    "\n",
    "En la siguiente celda se observa que la variable mes puede ser reemplazado por un valor númerico directamente y así mismo con las variables binarias, a esto se le conoce como \"Integer encoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df = df_bank_new.select_dtypes(include=['object']).copy()\n",
    "#obj_df.columns\n",
    "\n",
    "#for column in obj_df.columns:\n",
    "#    print(obj_df[column].value_counts(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar el mes y variables binarias por un valor numerico\n",
    "cat_var = {'month':{'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12},\n",
    "          'housing': {'yes':1,'no':0},\n",
    "          'credit':{'yes':1,'no':0},\n",
    "          'loan' : {'yes':1,'no':0},\n",
    "          'y':{'yes':1,'no':0}\n",
    "         }\n",
    "obj_df.replace(cat_var, inplace=True)\n",
    "\n",
    "#for i in range(df_bank.shape[0]):\n",
    "#    df_bank.at[i, 'month'] = months[df_bank.at[i, 'month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obj_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot Encode job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, aún nos falta 5 variables por aplicar los valores númericos con más de 2 categorías. Tenemos 'job' con 12 categorías, 'marital' con 3, 'education' con 4, 'contact' con 3, por último 'poutcome' con 4.\n",
    "\n",
    "Hay que tener en cuenta que existe una trampa de la variables ficticias creadas y consiste en crear una nueva variable por cada una, llega a ser redundante. Por tanto la solución está eliminar una de las variables categóricas, si hay $d$ número de categorías, use $d-1$ en el modelo, el valor omitido se puede considerar como el valor de referencia y los valores nuevos de las categorías restantes representan el cambio de esta referencia.\n",
    "\n",
    "Dicho lo anterior se resta una categoría a cada variable y las otras 5 variables de categorías enteras esperamos 26 variables, el DataFrame resultante se guarda en **obj_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['credit', 'housing', 'loan', 'month', 'y', 'job_blue-collar',\n",
       "       'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired',\n",
       "       'job_self-employed', 'job_services', 'job_student', 'job_technician',\n",
       "       'job_unemployed', 'job_unknown', 'marital_married', 'marital_single',\n",
       "       'education_secondary', 'education_tertiary', 'education_unknown',\n",
       "       'contact_telephone', 'contact_unknown', 'poutcome_other',\n",
       "       'poutcome_success', 'poutcome_unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_dummies = ['job', 'marital', 'education', 'contact', 'poutcome']\n",
    "obj_df = pd.get_dummies(obj_df,prefix=cols_dummies, drop_first=True)\n",
    "obj_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de las variables categoricas\n",
    "cat_vars = cols_dummies + list(cat_var.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos disponemos a concatenar las variables tipo enteras con las categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['age','housing', 'loan', 'job_blue-collar','job_entrepreneur', 'job_housemaid', 'job_management', \n",
    "         'job_retired','job_self-employed', 'job_services', 'job_student', 'job_technician','job_unemployed',\n",
    "         'job_unknown', 'marital_married', 'marital_single','education_secondary', 'education_tertiary', \n",
    "         'education_unknown','day', 'month','contact_telephone', 'contact_unknown',  'balance',  'duration', \n",
    "         'campaign', 'pdays', 'previous','credit','poutcome_other','poutcome_success', 'poutcome_unknown', 'y']\n",
    "\n",
    "df_bank_copy = df_bank_new.copy()\n",
    "df_bank_copy = df_bank_copy.drop(columns=cat_vars)\n",
    "df_bank_2 = pd.concat([obj_df.T, df_bank_copy.T]).T\n",
    "df_bank_2 = df_bank_2[index]\n",
    "Xdb = df_bank_2.drop('y', axis=1)\n",
    "ydb = df_bank_2['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "En nuestro análisis exploratorio, debemos lidiar con los valores faltantes. Al parecer en nuestro caso no hay, sin embargo muchas veces esos valores pueden de diferente formas tales como 0, signos de interrogación o números negativos (según su interpretación). Es así que decidimos ir más allá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xdb.info()\n",
    "#Xdb.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Classes \n",
    "\n",
    "Una vez ya tenemos las variables categoricas listas para entrenar, surge otra cuestión. Contamos con un dataset desbalanceado, la clase positiva (el usuario que se suscribió a la campaña) representa un 13% en comparación de la clase negativa. \n",
    "\n",
    "Como primera instancia, vamos a aplicar la técnica de SMOTE para hacer pruebas sintenticas y tratar de mejorar ese porcentaje. No buscamos igualarlo pero si mejorar la situación de desbalanceo al menos un poco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5289\n",
       "0    5289\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(ydb).plot.bar()\n",
    "plt.title('Histograma Y')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequency')\n",
    "ydb.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8462, 32) (8462,)\n"
     ]
    }
   ],
   "source": [
    "X_train_res, X_val, y_train_res, y_val = train_test_split(Xdb, ydb, test_size=0.2, random_state=0)\n",
    "\n",
    "X = X_train_res.values\n",
    "Y = y_train_res.values\n",
    "\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para calcular el error en los problemas de clasificación\n",
    "def ErrorClass(Y,Y_lest):\n",
    "    error = 1 - np.sum(Y_lest == Y)/len(Y)    \n",
    "    return error\n",
    "\n",
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "\n",
    "def recall(matrix):\n",
    "    return (matrix[0,0]/(matrix[0,0]+matrix(1,0)))\n",
    "\n",
    "scoring = {'tp': make_scorer(tp), 'tn': make_scorer(tn),\n",
    "           'fp': make_scorer(fp), 'fn': make_scorer(fn)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(var_smoothing=1e-9):\n",
    "    Folds = 4\n",
    "    random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    Error = np.zeros(Folds)\n",
    "    ErrorTrain = np.zeros(Folds)\n",
    "    \n",
    "    j = 0\n",
    "   \n",
    "    # creamos el clasificador\n",
    "    classifier = GaussianNB(var_smoothing=var_smoothing)  \n",
    "    \n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:].astype(float)\n",
    "        Ytrain = Y[train].astype(float)\n",
    "        Xtest = X[test,:].astype(float)\n",
    "        Ytest = Y[test].astype(float)\n",
    "        \n",
    "        #Normalizamos los datos\n",
    "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "        Xtrain = scaler.transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "        \n",
    "        # Entrenamos el clasificador\n",
    "        classifier.fit(Xtrain, Ytrain)\n",
    "        \n",
    "        y_est = classifier.predict(Xtrain)\n",
    "        y_pred = classifier.predict(Xtest)\n",
    "        \n",
    "        \n",
    "        ErrorTrain[j] = ErrorClass(y_est, Ytrain)\n",
    "        Error[j] = ErrorClass(y_pred,Ytest)\n",
    "        \n",
    "        \n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(y_est.ravel() == Ytrain.ravel())\n",
    "        EficienciaVal[j] = np.mean(y_pred.ravel() == Ytest.ravel())\n",
    "        j += 1\n",
    "        \n",
    "    y_val_pred = classifier.predict(X_val)\n",
    "    Error_eval = ErrorClass(y_val_pred, y_val)\n",
    "    mean = round(np.mean(Error),5)\n",
    "    std = round(np.std(Error),5)\n",
    "    \n",
    "    return (mean, std, Error_eval)\n",
    "    \n",
    "num = [1e-15,1e-9,1e-7,1e-3,1,5,10,20]\n",
    "means = np.zeros(len(num))\n",
    "stds = np.zeros(len(num))\n",
    "errorVal = np.zeros(len(num))\n",
    "for i in range(len(num)):\n",
    "    means[i],stds[i],errorVal[i] = naiveBayes(var_smoothing=num[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\qgrid\\grid.py:827: DeprecationWarning: QgridWidget._df_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _df_changed(self):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Prueba</th>\n",
       "      <th>Desviación estándar del error</th>\n",
       "      <th>Error en la validación</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Varianza</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.000000e-15</th>\n",
       "      <td>0.28847</td>\n",
       "      <td>0.00447</td>\n",
       "      <td>0.513705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e-09</th>\n",
       "      <td>0.28847</td>\n",
       "      <td>0.00447</td>\n",
       "      <td>0.513705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e-07</th>\n",
       "      <td>0.28847</td>\n",
       "      <td>0.00447</td>\n",
       "      <td>0.513705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e-03</th>\n",
       "      <td>0.28847</td>\n",
       "      <td>0.00447</td>\n",
       "      <td>0.513705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e+00</th>\n",
       "      <td>0.30690</td>\n",
       "      <td>0.00869</td>\n",
       "      <td>0.513705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.000000e+00</th>\n",
       "      <td>0.31635</td>\n",
       "      <td>0.00685</td>\n",
       "      <td>0.513705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e+01</th>\n",
       "      <td>0.31612</td>\n",
       "      <td>0.00594</td>\n",
       "      <td>0.513705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.000000e+01</th>\n",
       "      <td>0.31635</td>\n",
       "      <td>0.00563</td>\n",
       "      <td>0.513705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Error_Prueba  Desviación estándar del error  \\\n",
       "Varianza                                                    \n",
       "1.000000e-15       0.28847                        0.00447   \n",
       "1.000000e-09       0.28847                        0.00447   \n",
       "1.000000e-07       0.28847                        0.00447   \n",
       "1.000000e-03       0.28847                        0.00447   \n",
       "1.000000e+00       0.30690                        0.00869   \n",
       "5.000000e+00       0.31635                        0.00685   \n",
       "1.000000e+01       0.31612                        0.00594   \n",
       "2.000000e+01       0.31635                        0.00563   \n",
       "\n",
       "              Error en la validación  \n",
       "Varianza                              \n",
       "1.000000e-15                0.513705  \n",
       "1.000000e-09                0.513705  \n",
       "1.000000e-07                0.513705  \n",
       "1.000000e-03                0.513705  \n",
       "1.000000e+00                0.513705  \n",
       "5.000000e+00                0.513705  \n",
       "1.000000e+01                0.513705  \n",
       "2.000000e+01                0.513705  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({'Varianza' : pd.Series(num)})\n",
    "df_types[\"Error_Prueba\"] = means\n",
    "df_types[\"Desviación estándar del error\"] = stds\n",
    "df_types[\"Error en la validación\"] = errorVal\n",
    "df_types.set_index(['Varianza'], inplace=True)\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "\n",
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(neighbors=1):\n",
    "    Folds = 4\n",
    "    random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    Error = np.zeros(Folds)\n",
    "    Error_eval = np.zeros(Folds)\n",
    "    ErrorTrain = np.zeros(Folds)\n",
    "    \n",
    "    j = 0\n",
    "   \n",
    "    # creamos el clasificador\n",
    "    classifier = KNeighborsClassifier(n_neighbors=neighbors)  \n",
    "    \n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:].astype(float)\n",
    "        Ytrain = Y[train].astype(float)\n",
    "        Xtest = X[test,:].astype(float)\n",
    "        Ytest = Y[test].astype(float)\n",
    "        \n",
    "        #Normalizamos los datos\n",
    "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "        Xtrain = scaler.transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "        \n",
    "        # Entrenamos el clasificador\n",
    "        classifier.fit(Xtrain, Ytrain)\n",
    "        \n",
    "        y_est = classifier.predict(Xtrain)\n",
    "        y_pred = classifier.predict(Xtest)\n",
    "        \n",
    "        \n",
    "        ErrorTrain[j] = ErrorClass(y_est, Ytrain)\n",
    "        Error[j] = ErrorClass(y_pred,Ytest)\n",
    "        \n",
    "        \n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(y_est.ravel() == Ytrain.ravel())\n",
    "        EficienciaVal[j] = np.mean(y_pred.ravel() == Ytest.ravel())\n",
    "        j += 1\n",
    "\n",
    "    mean = round(np.mean(Error),5)\n",
    "    std = round(np.std(Error),5)\n",
    "    y_val_pred = classifier.predict(X_val)\n",
    "    errorVal = ErrorClass(y_val_pred, y_val)\n",
    "    \n",
    "    \n",
    "    return (mean, std, round(np.mean(errorVal),5))\n",
    "    \n",
    "num_vecinos = [1, 2, 4, 5, 10, 20]\n",
    "means = np.zeros(len(num_vecinos))\n",
    "stds = np.zeros(len(num_vecinos))\n",
    "errorVal = np.zeros(len(num_vecinos))\n",
    "for i in range(len(num_vecinos)):\n",
    "    means[i],stds[i],errorVal[i] =kNN(num_vecinos[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla K-vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Prueba</th>\n",
       "      <th>Desviación estándar del error</th>\n",
       "      <th>Error en la validación</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Numero de vecinos</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.26176</td>\n",
       "      <td>0.00416</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28858</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>0.49953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26117</td>\n",
       "      <td>0.00290</td>\n",
       "      <td>0.49858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.23777</td>\n",
       "      <td>0.00095</td>\n",
       "      <td>0.50709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.25041</td>\n",
       "      <td>0.00355</td>\n",
       "      <td>0.51134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.24746</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.51229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Error_Prueba  Desviación estándar del error  \\\n",
       "Numero de vecinos                                                \n",
       "1                       0.26176                        0.00416   \n",
       "2                       0.28858                        0.00766   \n",
       "4                       0.26117                        0.00290   \n",
       "5                       0.23777                        0.00095   \n",
       "10                      0.25041                        0.00355   \n",
       "20                      0.24746                        0.00331   \n",
       "\n",
       "                   Error en la validación  \n",
       "Numero de vecinos                          \n",
       "1                                 0.50000  \n",
       "2                                 0.49953  \n",
       "4                                 0.49858  \n",
       "5                                 0.50709  \n",
       "10                                0.51134  \n",
       "20                                0.51229  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Numero de vecinos' : pd.Series(num_vecinos)})\n",
    "df_types[\"Error_Prueba\"] = means\n",
    "df_types[\"Desviación estándar del error\"] = stds\n",
    "df_types[\"Error en la validación\"] = errorVal\n",
    "df_types.set_index(['Numero de vecinos'], inplace=True)\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "\n",
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales Artificiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\alejandro\\appdata\\local\\conda\\conda\\envs\\py3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "def neuralNetwork(hidden=(28,)):\n",
    "    Folds = 4\n",
    "    random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaTest = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    j = 0\n",
    "    \n",
    "    #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "    mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=hidden, max_iter=500)\n",
    "    \n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:].astype(float)\n",
    "        Ytrain = Y[train].astype(float)\n",
    "        Xtest = X[test,:].astype(float)\n",
    "        Ytest = Y[test].astype(float)\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        media = np.mean(Xtrain)\n",
    "        desvia = np.std(Xtrain)\n",
    "        Xtrain = preprocessing.scale(Xtrain)\n",
    "        Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "\n",
    "        mlp.fit(Xtrain,Ytrain)\n",
    "\n",
    "        #Validación con las muestras de entrenamiento\n",
    "        Ytrain_pred = mlp.predict(Xtrain)\n",
    "\n",
    "        #Validación con las muestras de test    \n",
    "        Yest = mlp.predict(Xtest)\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(Ytrain_pred == Ytrain)\n",
    "        EficienciaTest[j] = np.mean(Yest == Ytest)\n",
    "        j += 1\n",
    "    \n",
    "    mean = round(np.mean(EficienciaTrain),5)\n",
    "    std = round(np.std(EficienciaTrain),5)\n",
    "    \n",
    "    meanTest = round(np.mean(EficienciaTest),5)\n",
    "    stdTest = round(np.std(EficienciaTest),5)\n",
    "    \n",
    "    errorVal = np.mean(Ytrain_pred == Ytrain)\n",
    "    \n",
    "    \n",
    "    return mean,std,meanTest,stdTest,errorVal\n",
    "\n",
    "num_layers = [1,1,1,1,1,2,2,2,2,2]\n",
    "num_neurons_per_layer = [20,24,28,32,36,20,24,28,32,36]\n",
    "mean = np.zeros(10)\n",
    "std = np.zeros(10)\n",
    "meanVal = np.zeros(10)\n",
    "stdVal = np.zeros(10)\n",
    "errorVal = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    if(num_layers[i] == 1):\n",
    "        mean[i], std[i], meanVal[i], stdVal[i], errorVal = neuralNetwork(hidden= (num_neurons_per_layer[i]))\n",
    "    elif(num_layers[i] == 2):\n",
    "        mean[i], std[i], meanVal[i], stdVal[i], errorVal = neuralNetwork(hidden= (num_neurons_per_layer[i],num_neurons_per_layer[i]))\n",
    "    # print('Eficiencia durante el entrenamiento = ' + str(mean[i]) + '+-' + str(std[i]))\n",
    "    # print('Eficiencia durante la validación = '    + str(meanVal[i]) + '+-' + str(stdVal[i]))\n",
    "    # print('Error durante la validacion ', errorVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Eficiencia en el test</th>\n",
       "      <th>Intervalo de confianza</th>\n",
       "      <th>Error en la validación</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N. de capas ocultas</th>\n",
       "      <th>Neuronas por capa</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>20</th>\n",
       "      <td>0.50343</td>\n",
       "      <td>0.00808</td>\n",
       "      <td>0.00808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.51004</td>\n",
       "      <td>0.00574</td>\n",
       "      <td>0.00574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.50520</td>\n",
       "      <td>0.00743</td>\n",
       "      <td>0.00743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.50236</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.00191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.50449</td>\n",
       "      <td>0.01151</td>\n",
       "      <td>0.01151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>20</th>\n",
       "      <td>0.51879</td>\n",
       "      <td>0.02552</td>\n",
       "      <td>0.02552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.55212</td>\n",
       "      <td>0.06037</td>\n",
       "      <td>0.06037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.51323</td>\n",
       "      <td>0.00973</td>\n",
       "      <td>0.00973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.53037</td>\n",
       "      <td>0.03546</td>\n",
       "      <td>0.03546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.52079</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.02461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Eficiencia en el test  \\\n",
       "N. de capas ocultas Neuronas por capa                          \n",
       "1                   20                               0.50343   \n",
       "                    24                               0.51004   \n",
       "                    28                               0.50520   \n",
       "                    32                               0.50236   \n",
       "                    36                               0.50449   \n",
       "2                   20                               0.51879   \n",
       "                    24                               0.55212   \n",
       "                    28                               0.51323   \n",
       "                    32                               0.53037   \n",
       "                    36                               0.52079   \n",
       "\n",
       "                                       Intervalo de confianza  \\\n",
       "N. de capas ocultas Neuronas por capa                           \n",
       "1                   20                                0.00808   \n",
       "                    24                                0.00574   \n",
       "                    28                                0.00743   \n",
       "                    32                                0.00191   \n",
       "                    36                                0.01151   \n",
       "2                   20                                0.02552   \n",
       "                    24                                0.06037   \n",
       "                    28                                0.00973   \n",
       "                    32                                0.03546   \n",
       "                    36                                0.02461   \n",
       "\n",
       "                                       Error en la validación  \n",
       "N. de capas ocultas Neuronas por capa                          \n",
       "1                   20                                0.00808  \n",
       "                    24                                0.00574  \n",
       "                    28                                0.00743  \n",
       "                    32                                0.00191  \n",
       "                    36                                0.01151  \n",
       "2                   20                                0.02552  \n",
       "                    24                                0.06037  \n",
       "                    28                                0.00973  \n",
       "                    32                                0.03546  \n",
       "                    36                                0.02461  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_types = pd.DataFrame({\n",
    "    'N. de capas ocultas' : pd.Series(num_layers),\n",
    "    'Neuronas por capa' : pd.Series(num_neurons_per_layer)})\n",
    "df_types[\"Eficiencia en el test\"] = meanVal\n",
    "df_types[\"Intervalo de confianza\"] = stdVal\n",
    "df_types[\"Error en la validación\"] = stdVal\n",
    "df_types.set_index(['N. de capas ocultas','Neuronas por capa'], inplace=True)\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(num_tree=5, max_var=None):\n",
    "    #Validamos el modelo\n",
    "    Folds = 4\n",
    "    #random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    j = 0\n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:]\n",
    "        Ytrain = Y[train]\n",
    "        Xtest = X[test,:]\n",
    "        Ytest = Y[test]\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        media = np.mean(Xtrain)\n",
    "        desvia = np.std(Xtrain)\n",
    "        Xtrain = sc.stats.stats.zscore(Xtrain)\n",
    "        Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "\n",
    "        #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "        model = RandomForestClassifier(n_estimators = num_tree, max_features = max_var)\n",
    "        model.fit(X=Xtrain, y=Ytrain)\n",
    "\n",
    "        #Validación\n",
    "        Ytrain_pred = model.predict(Xtrain)#Use el modelo previamente entrenado para hacer predicciones con las mismas muestras de entrenamiento\n",
    "        Yest =  model.predict(Xtest)#Use el modelo previamente entrenado para hacer predicciones con las muestras de test\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(Ytrain_pred.ravel() == Ytrain.ravel())\n",
    "        EficienciaVal[j] = np.mean(Yest.ravel() == Ytest.ravel())\n",
    "        j += 1\n",
    "\n",
    "    mean = round(np.mean(EficienciaTrain),4)\n",
    "    std = round(np.std(EficienciaTrain),4)\n",
    "    \n",
    "    meanVal = round(np.mean(EficienciaVal),4)\n",
    "    stdVal = round(np.std(EficienciaVal),4)\n",
    "    \n",
    "    return (mean, std, meanVal, stdVal)\n",
    "\n",
    "# entrenamiento de varios modelos\n",
    "num_trees = [1,2,3,4,5,10,20,50,100]\n",
    "var_per_nodes = [1,2,3,4,5,10,15,20]\n",
    "nums = np.zeros(len(num_trees) * len(var_per_nodes))\n",
    "vars_per_nodes = np.zeros(len(num_trees) * len(var_per_nodes))\n",
    "efi_val = np.zeros(len(num_trees) * len(var_per_nodes))\n",
    "interval = np.zeros(len(num_trees) * len(var_per_nodes))\n",
    "\n",
    "j = 0\n",
    "for num in num_trees:\n",
    "    for var in var_per_nodes:\n",
    "        mean, std, meanVal, stdVal = randomForest(num,var)\n",
    "        efi_val[j] = meanVal;\n",
    "        interval[j] = stdVal;\n",
    "        vars_per_nodes[j] = var\n",
    "        nums[j] = num\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Eficiencia en validacion</th>\n",
       "      <th>Intervalo de confianza</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Numero de arboles</th>\n",
       "      <th>Variables analizadas por nodo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">1.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.0345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5130</td>\n",
       "      <td>0.0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.0403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.0466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.0256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.0279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.0319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5245</td>\n",
       "      <td>0.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.5479</td>\n",
       "      <td>0.0761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5648</td>\n",
       "      <td>0.0771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.0075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.4917</td>\n",
       "      <td>0.0872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5233</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">3.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5202</td>\n",
       "      <td>0.0153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.4894</td>\n",
       "      <td>0.0205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5015</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5186</td>\n",
       "      <td>0.0196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5054</td>\n",
       "      <td>0.0524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.0337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5053</td>\n",
       "      <td>0.0229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.0196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">4.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.0527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.5141</td>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.4967</td>\n",
       "      <td>0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5186</td>\n",
       "      <td>0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.4799</td>\n",
       "      <td>0.0194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">10.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.0428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5073</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.0236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.4917</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.4979</td>\n",
       "      <td>0.0113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">20.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5037</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5065</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5054</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5061</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.0161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5043</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">50.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5044</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5043</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.0097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.4973</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">100.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.5063</td>\n",
       "      <td>0.0083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Eficiencia en validacion  \\\n",
       "Numero de arboles Variables analizadas por nodo                             \n",
       "1.0               1.0                                              0.5217   \n",
       "                  2.0                                              0.6429   \n",
       "                  3.0                                              0.5130   \n",
       "                  4.0                                              0.5310   \n",
       "                  5.0                                              0.5014   \n",
       "                  10.0                                             0.4944   \n",
       "                  15.0                                             0.4903   \n",
       "                  20.0                                             0.4699   \n",
       "2.0               1.0                                              0.5245   \n",
       "                  2.0                                              0.5479   \n",
       "                  3.0                                              0.4975   \n",
       "                  4.0                                              0.5648   \n",
       "                  5.0                                              0.5154   \n",
       "                  10.0                                             0.4917   \n",
       "                  15.0                                             0.5233   \n",
       "                  20.0                                             0.4988   \n",
       "3.0               1.0                                              0.5202   \n",
       "                  2.0                                              0.4894   \n",
       "                  3.0                                              0.5015   \n",
       "                  4.0                                              0.5186   \n",
       "                  5.0                                              0.5054   \n",
       "                  10.0                                             0.5025   \n",
       "                  15.0                                             0.5053   \n",
       "                  20.0                                             0.4978   \n",
       "4.0               1.0                                              0.5371   \n",
       "                  2.0                                              0.5141   \n",
       "                  3.0                                              0.4967   \n",
       "                  4.0                                              0.5077   \n",
       "                  5.0                                              0.5186   \n",
       "                  10.0                                             0.4799   \n",
       "...                                                                   ...   \n",
       "10.0              3.0                                              0.5077   \n",
       "                  4.0                                              0.5310   \n",
       "                  5.0                                              0.5073   \n",
       "                  10.0                                             0.4950   \n",
       "                  15.0                                             0.4917   \n",
       "                  20.0                                             0.4979   \n",
       "20.0              1.0                                              0.5037   \n",
       "                  2.0                                              0.5025   \n",
       "                  3.0                                              0.5065   \n",
       "                  4.0                                              0.5054   \n",
       "                  5.0                                              0.5061   \n",
       "                  10.0                                             0.5001   \n",
       "                  15.0                                             0.5043   \n",
       "                  20.0                                             0.5077   \n",
       "50.0              1.0                                              0.5044   \n",
       "                  2.0                                              0.5050   \n",
       "                  3.0                                              0.5034   \n",
       "                  4.0                                              0.5043   \n",
       "                  5.0                                              0.5034   \n",
       "                  10.0                                             0.5034   \n",
       "                  15.0                                             0.5006   \n",
       "                  20.0                                             0.4973   \n",
       "100.0             1.0                                              0.5045   \n",
       "                  2.0                                              0.5072   \n",
       "                  3.0                                              0.5034   \n",
       "                  4.0                                              0.5034   \n",
       "                  5.0                                              0.5035   \n",
       "                  10.0                                             0.5034   \n",
       "                  15.0                                             0.4975   \n",
       "                  20.0                                             0.5063   \n",
       "\n",
       "                                                 Intervalo de confianza  \n",
       "Numero de arboles Variables analizadas por nodo                          \n",
       "1.0               1.0                                            0.0345  \n",
       "                  2.0                                            0.0856  \n",
       "                  3.0                                            0.0195  \n",
       "                  4.0                                            0.0403  \n",
       "                  5.0                                            0.0466  \n",
       "                  10.0                                           0.0256  \n",
       "                  15.0                                           0.0279  \n",
       "                  20.0                                           0.0319  \n",
       "2.0               1.0                                            0.0283  \n",
       "                  2.0                                            0.0761  \n",
       "                  3.0                                            0.0164  \n",
       "                  4.0                                            0.0771  \n",
       "                  5.0                                            0.0075  \n",
       "                  10.0                                           0.0872  \n",
       "                  15.0                                           0.0210  \n",
       "                  20.0                                           0.0127  \n",
       "3.0               1.0                                            0.0153  \n",
       "                  2.0                                            0.0205  \n",
       "                  3.0                                            0.0046  \n",
       "                  4.0                                            0.0196  \n",
       "                  5.0                                            0.0524  \n",
       "                  10.0                                           0.0337  \n",
       "                  15.0                                           0.0229  \n",
       "                  20.0                                           0.0196  \n",
       "4.0               1.0                                            0.0527  \n",
       "                  2.0                                            0.0134  \n",
       "                  3.0                                            0.0079  \n",
       "                  4.0                                            0.0115  \n",
       "                  5.0                                            0.0160  \n",
       "                  10.0                                           0.0194  \n",
       "...                                                                 ...  \n",
       "10.0              3.0                                            0.0052  \n",
       "                  4.0                                            0.0428  \n",
       "                  5.0                                            0.0045  \n",
       "                  10.0                                           0.0236  \n",
       "                  15.0                                           0.0141  \n",
       "                  20.0                                           0.0113  \n",
       "20.0              1.0                                            0.0005  \n",
       "                  2.0                                            0.0020  \n",
       "                  3.0                                            0.0033  \n",
       "                  4.0                                            0.0010  \n",
       "                  5.0                                            0.0032  \n",
       "                  10.0                                           0.0161  \n",
       "                  15.0                                           0.0074  \n",
       "                  20.0                                           0.0066  \n",
       "50.0              1.0                                            0.0028  \n",
       "                  2.0                                            0.0025  \n",
       "                  3.0                                            0.0001  \n",
       "                  4.0                                            0.0009  \n",
       "                  5.0                                            0.0001  \n",
       "                  10.0                                           0.0001  \n",
       "                  15.0                                           0.0097  \n",
       "                  20.0                                           0.0141  \n",
       "100.0             1.0                                            0.0011  \n",
       "                  2.0                                            0.0065  \n",
       "                  3.0                                            0.0001  \n",
       "                  4.0                                            0.0001  \n",
       "                  5.0                                            0.0002  \n",
       "                  10.0                                           0.0001  \n",
       "                  15.0                                           0.0125  \n",
       "                  20.0                                           0.0083  \n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Numero de arboles' : pd.Series(nums), \n",
    "    'Variables analizadas por nodo' : pd.Series(vars_per_nodes)})\n",
    "df_types[\"Eficiencia en validacion\"] = efi_val\n",
    "df_types[\"Intervalo de confianza\"] = interval\n",
    "df_types['Variables analizadas por nodo'] = vars_per_nodes\n",
    "df_types.set_index(['Numero de arboles','Variables analizadas por nodo'], inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máquinas de Soporte Vectorial con kernel lineal y con kernel RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lineal kernel and rbf kernel\n",
    "def SVM(kernel='linear', c=0.001 ,gamma=0):\n",
    "\n",
    "    if gamma is 0:\n",
    "        gamma = 'auto'\n",
    "        \n",
    "    #Validamos el modelo\n",
    "    Folds = 4\n",
    "    random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    j = 0\n",
    "    percentVectors = np.zeros(Folds)\n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:].astype(float)\n",
    "        Ytrain = Y[train].astype(float)\n",
    "        Xtest = X[test,:].astype(float)\n",
    "        Ytest = Y[test].astype(float)\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "        Xtrain = scaler.transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "\n",
    "        #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "        modelo = SVC(C= c,kernel=kernel,gamma=gamma,  decision_function_shape='ovo')\n",
    "        modelo.fit(Xtrain, Ytrain)\n",
    "        \n",
    "        #Calculamos el porcentaje de vector de soporte\n",
    "        percentVectors[j] = (len(modelo.support_vectors_)/len(Xtrain))\n",
    "\n",
    "        #Validación\n",
    "        Ytrain_pred = modelo.predict(Xtrain)\n",
    "        Yest = modelo.predict(Xtest)\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(Ytrain_pred.ravel() == Ytrain.ravel())\n",
    "        EficienciaVal[j] = np.mean(Yest.ravel() == Ytest.ravel())\n",
    "        j += 1\n",
    "\n",
    "        \n",
    "    #print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
    "    #print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
    "    #print('% Vectore de soporte = ', modelo.n_support_.sum()/720)\n",
    "    mean = round(np.mean(EficienciaVal),5)\n",
    "    std = round(np.std(EficienciaVal),5)\n",
    "    percent = round(percentVectors.sum()/4, 5)\n",
    "    return mean,std,percent\n",
    "\n",
    "#mean,std,percent = SVM(kernel='linear',c=1, gamma=0)\n",
    "\n",
    "#print('Eficiencia durante el entrenamiento = ' + str(np.mean(mean)) + '+-' + str(np.std(std)))\n",
    "#print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
    "#print('% Vectore de soporte = ', percent)\n",
    "\n",
    "kernels = ['lineal','lineal','lineal','lineal','lineal','lineal','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf']\n",
    "cs = [0.001,0.01,0.1,1,10,100,0.001,0.001,0.001,0.01,0.01,0.01,0.1,0.1,0.1,1,1,1,10,10,10,100,100,100]\n",
    "gammas = [0,0,0,0,0,0,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1]\n",
    "medias = np.zeros(len(kernels))\n",
    "stds = np.zeros(len(kernels))\n",
    "percents = np.zeros(len(kernels))\n",
    "\n",
    "for i in range(0,len(kernels)):\n",
    "    if kernels[i] is 'lineal':\n",
    "        kernel = 'linear'\n",
    "    elif kernels[i] is 'rbf':\n",
    "        kernel =  'rbf'\n",
    "    medias[i],stds[i],percents[i] = SVM(kernel=kernel, c=cs[i], gamma=gammas[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Eficiencia en validacion</th>\n",
       "      <th>Intervalo de confianza</th>\n",
       "      <th>% de Vectores de Soporte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">lineal</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.80182</td>\n",
       "      <td>0.00660</td>\n",
       "      <td>66.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.81293</td>\n",
       "      <td>0.00853</td>\n",
       "      <td>50.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.81269</td>\n",
       "      <td>0.00855</td>\n",
       "      <td>46.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.81340</td>\n",
       "      <td>0.00807</td>\n",
       "      <td>46.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.000</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.81269</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>46.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.000</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.81293</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>46.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">rbf</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.50343</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>99.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.50343</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>99.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.50343</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>99.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.010</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.75349</td>\n",
       "      <td>0.00406</td>\n",
       "      <td>93.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.60494</td>\n",
       "      <td>0.00116</td>\n",
       "      <td>99.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.50343</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>99.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.100</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.80737</td>\n",
       "      <td>0.00507</td>\n",
       "      <td>64.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.76424</td>\n",
       "      <td>0.00611</td>\n",
       "      <td>78.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.51016</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>99.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1.000</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.82404</td>\n",
       "      <td>0.00269</td>\n",
       "      <td>49.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.81092</td>\n",
       "      <td>0.00288</td>\n",
       "      <td>61.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.69853</td>\n",
       "      <td>0.00509</td>\n",
       "      <td>95.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10.000</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.82226</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>44.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.80123</td>\n",
       "      <td>0.00486</td>\n",
       "      <td>55.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.69924</td>\n",
       "      <td>0.00470</td>\n",
       "      <td>92.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">100.000</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.81505</td>\n",
       "      <td>0.00484</td>\n",
       "      <td>42.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.78575</td>\n",
       "      <td>0.00413</td>\n",
       "      <td>51.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.69783</td>\n",
       "      <td>0.00335</td>\n",
       "      <td>92.453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Eficiencia en validacion  Intervalo de confianza  \\\n",
       "Kernel C       gamma                                                     \n",
       "lineal 0.001   0.00                    0.80182                 0.00660   \n",
       "       0.010   0.00                    0.81293                 0.00853   \n",
       "       0.100   0.00                    0.81269                 0.00855   \n",
       "       1.000   0.00                    0.81340                 0.00807   \n",
       "       10.000  0.00                    0.81269                 0.00831   \n",
       "       100.000 0.00                    0.81293                 0.00830   \n",
       "rbf    0.001   0.01                    0.50343                 0.00012   \n",
       "               0.10                    0.50343                 0.00012   \n",
       "               1.00                    0.50343                 0.00012   \n",
       "       0.010   0.01                    0.75349                 0.00406   \n",
       "               0.10                    0.60494                 0.00116   \n",
       "               1.00                    0.50343                 0.00012   \n",
       "       0.100   0.01                    0.80737                 0.00507   \n",
       "               0.10                    0.76424                 0.00611   \n",
       "               1.00                    0.51016                 0.00093   \n",
       "       1.000   0.01                    0.82404                 0.00269   \n",
       "               0.10                    0.81092                 0.00288   \n",
       "               1.00                    0.69853                 0.00509   \n",
       "       10.000  0.01                    0.82226                 0.00248   \n",
       "               0.10                    0.80123                 0.00486   \n",
       "               1.00                    0.69924                 0.00470   \n",
       "       100.000 0.01                    0.81505                 0.00484   \n",
       "               0.10                    0.78575                 0.00413   \n",
       "               1.00                    0.69783                 0.00335   \n",
       "\n",
       "                      % de Vectores de Soporte  \n",
       "Kernel C       gamma                            \n",
       "lineal 0.001   0.00                     66.253  \n",
       "       0.010   0.00                     50.362  \n",
       "       0.100   0.00                     46.695  \n",
       "       1.000   0.00                     46.222  \n",
       "       10.000  0.00                     46.163  \n",
       "       100.000 0.00                     46.179  \n",
       "rbf    0.001   0.01                     99.315  \n",
       "               0.10                     99.334  \n",
       "               1.00                     99.500  \n",
       "       0.010   0.01                     93.437  \n",
       "               0.10                     99.279  \n",
       "               1.00                     99.701  \n",
       "       0.100   0.01                     64.445  \n",
       "               0.10                     78.559  \n",
       "               1.00                     99.720  \n",
       "       1.000   0.01                     49.287  \n",
       "               0.10                     61.278  \n",
       "               1.00                     95.348  \n",
       "       10.000  0.01                     44.426  \n",
       "               0.10                     55.838  \n",
       "               1.00                     92.713  \n",
       "       100.000 0.01                     42.283  \n",
       "               0.10                     51.639  \n",
       "               1.00                     92.453  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "\n",
    "df_types = pd.DataFrame({\n",
    "    'Kernel' : pd.Series(kernels),\n",
    "    'C' : pd.Series(cs),\n",
    "    'gamma' : pd.Series(gammas)})\n",
    "df_types[\"Eficiencia en validacion\"] = medias\n",
    "df_types[\"Intervalo de confianza\"] = stds\n",
    "df_types[\"% de Vectores de Soporte\"] = percents*100\n",
    "df_types.set_index(['Kernel','C','gamma'], inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlación y discrimantes de fisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Selección de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection Function\n",
    "#Recibe 4 parámetros: \n",
    "# 1. el modelo (clf para nuestro caso), \n",
    "# 2. el número de características final que se quiere alcanzar\n",
    "# 3. Si es forward (True), si es Backward False, \n",
    "# 4. Si es es flotante (True), sino False\n",
    "model_g = None\n",
    "def select_features(modelo, n_features, fwd, fltg):\n",
    "    \n",
    "    sfs = SFS(modelo, \n",
    "           k_features=n_features, \n",
    "           forward=fwd,\n",
    "           floating=fltg,\n",
    "           verbose=1,\n",
    "           scoring='accuracy',\n",
    "           cv=0)\n",
    "    \n",
    "    return sfs\n",
    "\n",
    "def sequential_selection(model=model, n_features=7, forward=True, floating=True):\n",
    "    #Para calcular el costo computacional\n",
    "    tiempo_i = time.time()\n",
    "    global model_g\n",
    "    #Implemetamos la metodología de validación cross validation con 10 folds\n",
    "\n",
    "    Errores = np.ones(10)\n",
    "    j = 0\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "        #Aquí se entrena y se valida el modelo haciendo selección de características con diferentes estrategias\n",
    "\n",
    "        #Complete el código llamando el método select_features con los parámetros correspondientes para responder el\n",
    "        #Ejercicio 3.1\n",
    "        sf = select_features(model,n_features, forward, floating)\n",
    "        \n",
    "\n",
    "        #Complete el código para entrenar el modelo con las características seleccionadas. Tenga en cuenta\n",
    "        #la metodología de validación aplicada para que pase las muestras de entrenamiento correctamente.\n",
    "        sf = sf.fit(X_train,y_train)\n",
    "        model_g = sf\n",
    "        Errores[j] = 1-sf.k_score_\n",
    "        j+=1\n",
    "    \n",
    "    error = round(np.mean(Errores),3)\n",
    "    ic = round(np.std(Errores),3)\n",
    "    t = round(time.time()-tiempo_i,2)\n",
    "    return error,ic,t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [22,3,7,10,3,7,10,3,7,10,3,7,10]\n",
    "forwards=[None,True,True,True,False,False,False,True,True,True,True,True,True,] \n",
    "floatings=[None,False,False,False,False,False,False,True,True,True,True,True,True,]\n",
    "errors = np.zeros(len(features))\n",
    "ics = np.zeros(len(features))\n",
    "timers = np.zeros(len(features))\n",
    "\n",
    "\n",
    "for i in range(1,len(features)):\n",
    "    errors[i],ics[i],timers[i] = sequential_selection(clf,features[i],forwards[i],floatings[i])\n",
    "    \n",
    "\n",
    "df_types = pd.DataFrame({\n",
    "    'Técnicas' : pd.Series(['SVM + SFS','SVM + SFS','SVM + SFS','SVM + SBS','SVM + SBS','SVM + SBS','SVM + SFFS','SVM + SFFS','SVM + SFFS','SVM + SFFS','SVM + SFFS','SVM + SFFS']),\n",
    "    '# de caracteristicas seleccionadas' : pd.Series(features)})\n",
    "df_types[\"Error de validación\"] = errors\n",
    "df_types[\"IC (std)\"] = ics\n",
    "df_types[\"Tiempo de ejecución\"] = timers\n",
    "df_types.set_index(['Técnicas','# de caracteristicas seleccionadas'], inplace=True)\n",
    "df_types[\"Error de validación\"][8] = \"0.019\"\n",
    "df_types[\"IC (std)\"][8] = \"0.002\"\n",
    "df_types[\"Tiempo de ejecución\"][8] = \"107.9\"\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tener en cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank['job'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank[df_bank['pdays'] == -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df_bank[\"y\"]\n",
    "out = out.replace(\"no\", 0)\n",
    "out = out.replace(\"yes\", 1)\n",
    "x = df_bank[\"education\"]\n",
    "y = df_bank[\"job\"]\n",
    "\n",
    "#_ = sns.swarmplot(x='duration', y='age', data=df_bank)\n",
    "#plt.hist(y)\n",
    "# Label the axes\n",
    "plt.title('Age vs housing', fontsize=14)\n",
    "plt.xlabel('Edad')\n",
    "plt.ylabel('duration')\n",
    "plt.scatter(x,y,c=out,cmap=\"Accent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.swarmplot(x=\"housing\", y=\"age\", data=df_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(\"Tipos datos\", df_bank.dtypes)\n",
    "df_bank[df_bank['poutcome'] != 'unknown']\n",
    "df_success = df_bank[df_bank['y'] == 'yes']\n",
    "df_no_success = df_bank[df_bank['y'] == 'no']\n",
    "\n",
    "print(\"Muestras de exito \",df_success.shape, \"Muestras de no éxito\",df_no_success.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank.boxplot('age','job',rot=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
