{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "\n",
    "\n",
    "### Intuición\n",
    "\n",
    "AdaBost, es la contracción de \"*Adaptative Boosting*\".  El término boosting se conoce como el algoritmo que encuentra una hipótesis fuerte a partir de hipótesis simples y débiles. En este caso consiste en una combinación lineal de predictores débiles hasta llegar a un predictor fuerte.\n",
    "\n",
    "AdaBost, llega al mejor modelo $H_T$ através de la suma de clasificadores debiles $h_t$ conocidos como \"weark learner\" (modelos que son un poco mejor que las suposiciones aleatorias de árboles de decisión) en una serie de iteraciones de $1,... , T$. \n",
    "\n",
    "Las prediciones se combinan a través de un voto o una suma ponderada para producir la predición final.\n",
    "\n",
    "\n",
    "En cada iteración se realiza una modificación en las muestras, consiste en la aplicación de pesos $w_1, w_2,...., w_N$ a cada una de las muestras $i$ de entrenamiento. La distribuición de los pesos $D_t(i)$ en un principio es equitativa de la forma $w_i = 1/N$, pero en cada iteración los pesos de la muestras clasificadas incorrectamente se incrementa en el clasificador débil siguiente mientras que los ejemplos de entrenamiento pronosticados correctamente reduce su peso, esto permite que el $h_t$ se concentre en las muestras \"difíciles\" de predecir con una influencia cada vez mayor .\n",
    "\n",
    "\n",
    "### Entrenamiento\n",
    "\n",
    "AdaBost se refiere a un método partifcular de entrenamiento de \"boosting\", tiene la siguiente forma:\n",
    "\n",
    "$H_t (x) = \\sum_{t=1}^{T} h_t ({x})$\n",
    "\n",
    "donde cada clasificador débil \n",
    "\n",
    "Cada clasificador débil produce una hipotesis de salida $h (x_i) $ por cada muestra en el conjunto de entrenamiento. Así mismo en cada iteración $t$, el weak learner selecciona y asigna un coeficiente $w$ tal que la suma de error de entreamiento $E_t$ resultante en la etapa $t$ del clasificador boost es minizado.\n",
    "\n",
    "$E$\n",
    "\n",
    "\n",
    "### Algoritmo\n",
    "\n",
    "\n",
    "* Dado: $(x_1, y_1) , ... , (x_N, y_N)$ donde $x_i \\in X$, $y_i \\in Y = {1,2}$\n",
    "\n",
    "\n",
    "* Se inicializa los pesos $w_i$ de la forma $D_1(i) = 1/N$\n",
    "\n",
    "\n",
    "* En cada iteración  $t = 1, ..., T:$\n",
    "\n",
    "** holi\n",
    "\n",
    "\n",
    "\n",
    "Es un popular algoritmo introducido en el año 1995 por Freund y Schapire\n",
    "\n",
    "Usamos la distribucion débil para el entretamiento\n",
    "\n",
    "#### Error de la hipotesis débil\n",
    "\n",
    "$$\\epsilon _t=\\mathbf{Pr}_{i\\sim D_t}\\left [ h_t(x_i)\\neq y_i \\right ]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 [[0.00666667]\n",
      " [0.00666667]\n",
      " [0.00666667]\n",
      " [0.00666667]\n",
      " [0.00666667]\n",
      " [0.00666667]\n",
      " [0.00666667]\n",
      " [0.00666667]\n",
      " [0.00666667]\n",
      " [0.00666667]]\n"
     ]
    }
   ],
   "source": [
    "#cargamos la bd iris desde el dataset de sklearn\n",
    "from sklearn import datasets\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#Esta es la base de datos Iris del UCI Machine Learning Repository \n",
    "#https://archive.ics.uci.edu/ml/datasets/iris\n",
    "\n",
    "X, Y = iris.data, iris.target\n",
    "\n",
    "# numero de hipotesisdebiles\n",
    "T = 10\n",
    "# Numero total de muestras\n",
    "M = X.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "# Array de pesos inicial\n",
    "weights = np.ones((T,1)) * 1/M\n",
    "\n",
    "print(M, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_t(e_t):\n",
    "    return (0.5 * np.log((1 - e_t) / e_t))\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
